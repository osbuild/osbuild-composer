// Package v2 provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.1 DO NOT EDIT.
package v2

import (
	"bytes"
	"compress/gzip"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"net/http"
	"net/url"
	"path"
	"strings"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/labstack/echo/v4"
	"github.com/oapi-codegen/runtime"
	openapi_types "github.com/oapi-codegen/runtime/types"
)

const (
	BearerScopes = "Bearer.Scopes"
)

// Defines values for AzureUploadOptionsHyperVGeneration.
const (
	V1 AzureUploadOptionsHyperVGeneration = "V1"
	V2 AzureUploadOptionsHyperVGeneration = "V2"
)

// Defines values for BlueprintCustomizationsPartitioningMode.
const (
	BlueprintCustomizationsPartitioningModeAutoLvm BlueprintCustomizationsPartitioningMode = "auto-lvm"
	BlueprintCustomizationsPartitioningModeLvm     BlueprintCustomizationsPartitioningMode = "lvm"
	BlueprintCustomizationsPartitioningModeRaw     BlueprintCustomizationsPartitioningMode = "raw"
)

// Defines values for BtrfsVolumeType.
const (
	Btrfs BtrfsVolumeType = "btrfs"
)

// Defines values for ComposeStatusValue.
const (
	ComposeStatusValueFailure ComposeStatusValue = "failure"
	ComposeStatusValuePending ComposeStatusValue = "pending"
	ComposeStatusValueSuccess ComposeStatusValue = "success"
)

// Defines values for CustomizationsPartitioningMode.
const (
	CustomizationsPartitioningModeAutoLvm CustomizationsPartitioningMode = "auto-lvm"
	CustomizationsPartitioningModeLvm     CustomizationsPartitioningMode = "lvm"
	CustomizationsPartitioningModeRaw     CustomizationsPartitioningMode = "raw"
)

// Defines values for DiskType.
const (
	DiskTypeDos DiskType = "dos"
	DiskTypeGpt DiskType = "gpt"
)

// Defines values for FilesystemTypedFsType.
const (
	FilesystemTypedFsTypeExt4 FilesystemTypedFsType = "ext4"
	FilesystemTypedFsTypeSwap FilesystemTypedFsType = "swap"
	FilesystemTypedFsTypeVfat FilesystemTypedFsType = "vfat"
	FilesystemTypedFsTypeXfs  FilesystemTypedFsType = "xfs"
)

// Defines values for FilesystemTypedType.
const (
	Plain FilesystemTypedType = "plain"
)

// Defines values for ImageSBOMPipelinePurpose.
const (
	Buildroot ImageSBOMPipelinePurpose = "buildroot"
	Image     ImageSBOMPipelinePurpose = "image"
)

// Defines values for ImageSBOMSbomType.
const (
	Spdx ImageSBOMSbomType = "spdx"
)

// Defines values for ImageStatusValue.
const (
	ImageStatusValueBuilding    ImageStatusValue = "building"
	ImageStatusValueFailure     ImageStatusValue = "failure"
	ImageStatusValuePending     ImageStatusValue = "pending"
	ImageStatusValueRegistering ImageStatusValue = "registering"
	ImageStatusValueSuccess     ImageStatusValue = "success"
	ImageStatusValueUploading   ImageStatusValue = "uploading"
)

// Defines values for ImageTypeInfoBootMode.
const (
	Hybrid ImageTypeInfoBootMode = "hybrid"
	Legacy ImageTypeInfoBootMode = "legacy"
	None   ImageTypeInfoBootMode = "none"
	Uefi   ImageTypeInfoBootMode = "uefi"
)

// Defines values for ImageTypeInfoPartitionType.
const (
	ImageTypeInfoPartitionTypeDos ImageTypeInfoPartitionType = "dos"
	ImageTypeInfoPartitionTypeGpt ImageTypeInfoPartitionType = "gpt"
)

// Defines values for ImageTypes.
const (
	ImageTypesAws                    ImageTypes = "aws"
	ImageTypesAwsHaRhui              ImageTypes = "aws-ha-rhui"
	ImageTypesAwsRhui                ImageTypes = "aws-rhui"
	ImageTypesAwsSapRhui             ImageTypes = "aws-sap-rhui"
	ImageTypesAzure                  ImageTypes = "azure"
	ImageTypesAzureCvm               ImageTypes = "azure-cvm"
	ImageTypesAzureEap7Rhui          ImageTypes = "azure-eap7-rhui"
	ImageTypesAzureRhui              ImageTypes = "azure-rhui"
	ImageTypesAzureSapRhui           ImageTypes = "azure-sap-rhui"
	ImageTypesAzureSapappsRhui       ImageTypes = "azure-sapapps-rhui"
	ImageTypesEdgeCommit             ImageTypes = "edge-commit"
	ImageTypesEdgeContainer          ImageTypes = "edge-container"
	ImageTypesEdgeInstaller          ImageTypes = "edge-installer"
	ImageTypesGcp                    ImageTypes = "gcp"
	ImageTypesGcpRhui                ImageTypes = "gcp-rhui"
	ImageTypesGuestImage             ImageTypes = "guest-image"
	ImageTypesImageInstaller         ImageTypes = "image-installer"
	ImageTypesIotBootableContainer   ImageTypes = "iot-bootable-container"
	ImageTypesIotCommit              ImageTypes = "iot-commit"
	ImageTypesIotContainer           ImageTypes = "iot-container"
	ImageTypesIotInstaller           ImageTypes = "iot-installer"
	ImageTypesIotRawImage            ImageTypes = "iot-raw-image"
	ImageTypesIotSimplifiedInstaller ImageTypes = "iot-simplified-installer"
	ImageTypesLiveInstaller          ImageTypes = "live-installer"
	ImageTypesMinimalRaw             ImageTypes = "minimal-raw"
	ImageTypesNetworkInstaller       ImageTypes = "network-installer"
	ImageTypesOci                    ImageTypes = "oci"
	ImageTypesPxeTarXz               ImageTypes = "pxe-tar-xz"
	ImageTypesVsphere                ImageTypes = "vsphere"
	ImageTypesVsphereOva             ImageTypes = "vsphere-ova"
	ImageTypesWsl                    ImageTypes = "wsl"
)

// Defines values for LogicalVolumeFsType.
const (
	LogicalVolumeFsTypeExt4 LogicalVolumeFsType = "ext4"
	LogicalVolumeFsTypeSwap LogicalVolumeFsType = "swap"
	LogicalVolumeFsTypeVfat LogicalVolumeFsType = "vfat"
	LogicalVolumeFsTypeXfs  LogicalVolumeFsType = "xfs"
)

// Defines values for UploadStatusValue.
const (
	Failure UploadStatusValue = "failure"
	Pending UploadStatusValue = "pending"
	Running UploadStatusValue = "running"
	Success UploadStatusValue = "success"
)

// Defines values for UploadTypes.
const (
	UploadTypesAws              UploadTypes = "aws"
	UploadTypesAwsS3            UploadTypes = "aws.s3"
	UploadTypesAzure            UploadTypes = "azure"
	UploadTypesContainer        UploadTypes = "container"
	UploadTypesGcp              UploadTypes = "gcp"
	UploadTypesLocal            UploadTypes = "local"
	UploadTypesOciObjectstorage UploadTypes = "oci.objectstorage"
)

// Defines values for VolumeGroupType.
const (
	Lvm VolumeGroupType = "lvm"
)

// AWSEC2CloneCompose defines model for AWSEC2CloneCompose.
type AWSEC2CloneCompose struct {
	Region            string    `json:"region"`
	ShareWithAccounts *[]string `json:"share_with_accounts,omitempty"`
}

// AWSEC2UploadOptions defines model for AWSEC2UploadOptions.
type AWSEC2UploadOptions struct {
	Region            string   `json:"region"`
	ShareWithAccounts []string `json:"share_with_accounts"`
	SnapshotName      *string  `json:"snapshot_name,omitempty"`
}

// AWSEC2UploadStatus defines model for AWSEC2UploadStatus.
type AWSEC2UploadStatus struct {
	Ami    string `json:"ami"`
	Region string `json:"region"`
}

// AWSS3UploadOptions defines model for AWSS3UploadOptions.
type AWSS3UploadOptions struct {
	// Public If set to false (the default value), a long, obfuscated URL
	// is returned. Its expiration might be sooner than for other upload
	// targets.
	//
	// If set to true, a shorter URL is returned and
	// its expiration is the same as for the other upload targets.
	Public *bool  `json:"public,omitempty"`
	Region string `json:"region"`
}

// AWSS3UploadStatus defines model for AWSS3UploadStatus.
type AWSS3UploadStatus struct {
	Url string `json:"url"`
}

// ArchitectureInfo Architecture metadata from images library
type ArchitectureInfo struct {
	// ImageTypes Map of image type names to their details
	ImageTypes *map[string]ImageTypeInfo `json:"image_types,omitempty"`

	// Name Architecture name
	Name string `json:"name"`
}

// AzureUploadOptions defines model for AzureUploadOptions.
type AzureUploadOptions struct {
	// HyperVGeneration Choose the VM Image HyperV generation, different features on Azure are available
	// depending on the HyperV generation.
	HyperVGeneration *AzureUploadOptionsHyperVGeneration `json:"hyper_v_generation,omitempty"`

	// ImageName Name of the uploaded image. It must be unique in the given resource group.
	// If name is omitted from the request, a random one based on a UUID is
	// generated.
	ImageName *string `json:"image_name,omitempty"`

	// Location Location of the provided resource_group, where the image should be uploaded and registered.
	// How to list all locations:
	// https://docs.microsoft.com/en-us/cli/azure/account?view=azure-cli-latest#az_account_list_locations'
	// If the location is not specified, it is deducted from the provided resource_group.
	Location *string `json:"location,omitempty"`

	// ResourceGroup Name of the resource group where the image should be uploaded.
	ResourceGroup string `json:"resource_group"`

	// SubscriptionId ID of subscription where the image should be uploaded.
	SubscriptionId string `json:"subscription_id"`

	// TenantId ID of the tenant where the image should be uploaded.
	// How to find it in the Azure Portal:
	// https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-how-to-find-tenant
	TenantId string `json:"tenant_id"`
}

// AzureUploadOptionsHyperVGeneration Choose the VM Image HyperV generation, different features on Azure are available
// depending on the HyperV generation.
type AzureUploadOptionsHyperVGeneration string

// AzureUploadStatus defines model for AzureUploadStatus.
type AzureUploadStatus struct {
	ImageName string `json:"image_name"`
}

// Blueprint defines model for Blueprint.
type Blueprint struct {
	// Containers Container images to embed into the final artfact
	Containers     *[]Container             `json:"containers,omitempty"`
	Customizations *BlueprintCustomizations `json:"customizations,omitempty"`
	Description    *string                  `json:"description,omitempty"`

	// Distro The distribution to use for the compose. If left empty the host
	// distro will be used.
	Distro         *string   `json:"distro,omitempty"`
	EnabledModules *[]Module `json:"enabled_modules,omitempty"`

	// Groups Package groups to be installed
	Groups *[]PackageGroup `json:"groups,omitempty"`

	// Modules An alias for packages, retained for backwards compatability
	Modules *[]Package `json:"modules,omitempty"`
	Name    string     `json:"name"`

	// Packages Packages to be installed
	Packages *[]Package `json:"packages,omitempty"`

	// Version A semver version number
	Version *string `json:"version,omitempty"`
}

// BlueprintCustomizations defines model for BlueprintCustomizations.
type BlueprintCustomizations struct {
	Cacerts *CACertsCustomization `json:"cacerts,omitempty"`

	// Directories Directories to create in the final artifact
	Directories *[]Directory `json:"directories,omitempty"`
	Disk        *Disk        `json:"disk,omitempty"`
	DNF         *DNF         `json:"dnf,omitempty"`

	// Fdo FIDO device onboard configuration
	Fdo *FDO `json:"fdo,omitempty"`

	// Files Files to create in the final artifact
	Files *[]BlueprintFile `json:"files,omitempty"`

	// Filesystem List of filesystem mountpoints to create
	Filesystem *[]BlueprintFilesystem `json:"filesystem,omitempty"`

	// Fips Enable FIPS mode
	Fips *bool `json:"fips,omitempty"`

	// Firewall Firewalld configuration
	Firewall *BlueprintFirewall `json:"firewall,omitempty"`

	// Group List of groups to create
	Group *[]Group `json:"group,omitempty"`

	// Hostname Configures the hostname
	Hostname *string `json:"hostname,omitempty"`

	// Ignition Ignition configuration
	Ignition *Ignition `json:"ignition,omitempty"`

	// InstallationDevice Name of the installation device, currently only useful for the edge-simplified-installer type
	InstallationDevice *string    `json:"installation_device,omitempty"`
	Installer          *Installer `json:"installer,omitempty"`
	Kernel             *Kernel    `json:"kernel,omitempty"`

	// Locale Locale configuration
	Locale   *Locale            `json:"locale,omitempty"`
	Openscap *BlueprintOpenSCAP `json:"openscap,omitempty"`

	// PartitioningMode Select how the disk image will be partitioned. 'auto-lvm' will use raw unless
	// there are one or more mountpoints in which case it will use LVM. 'lvm' always
	// uses LVM, even when there are no extra mountpoints. 'raw' uses raw partitions
	// even when there are one or more mountpoints.
	PartitioningMode *BlueprintCustomizationsPartitioningMode `json:"partitioning_mode,omitempty"`

	// Repositories Repositories to write to /etc/yum.repos.d/ in the final image. Note
	// that these are not used at build time.
	Repositories *[]BlueprintRepository `json:"repositories,omitempty"`
	Rhsm         *RHSMCustomization     `json:"rhsm,omitempty"`
	Rpm          *RPMCustomization      `json:"rpm,omitempty"`
	Services     *Services              `json:"services,omitempty"`

	// Sshkey List of ssh keys
	Sshkey *[]SSHKey `json:"sshkey,omitempty"`

	// Timezone Timezone configuration
	Timezone *Timezone `json:"timezone,omitempty"`

	// User List of users to create
	User *[]BlueprintUser `json:"user,omitempty"`
}

// BlueprintCustomizationsPartitioningMode Select how the disk image will be partitioned. 'auto-lvm' will use raw unless
// there are one or more mountpoints in which case it will use LVM. 'lvm' always
// uses LVM, even when there are no extra mountpoints. 'raw' uses raw partitions
// even when there are one or more mountpoints.
type BlueprintCustomizationsPartitioningMode string

// BlueprintFile A custom file to create in the final artifact.
type BlueprintFile struct {
	// Data Contents of the file as plain text
	Data *string `json:"data,omitempty"`

	// Group Group of the file as a gid or a group name
	Group *BlueprintFile_Group `json:"group,omitempty"`

	// Mode Permissions string for the file in octal format
	Mode *string `json:"mode,omitempty"`

	// Path Path to the file
	Path string `json:"path"`

	// User Owner of the file as a uid or a user name
	User *BlueprintFile_User `json:"user,omitempty"`
}

// BlueprintFileGroup0 defines model for .
type BlueprintFileGroup0 = string

// BlueprintFileGroup1 defines model for .
type BlueprintFileGroup1 = int64

// BlueprintFile_Group Group of the file as a gid or a group name
type BlueprintFile_Group struct {
	union json.RawMessage
}

// BlueprintFileUser0 defines model for .
type BlueprintFileUser0 = string

// BlueprintFileUser1 defines model for .
type BlueprintFileUser1 = int64

// BlueprintFile_User Owner of the file as a uid or a user name
type BlueprintFile_User struct {
	union json.RawMessage
}

// BlueprintFilesystem defines model for BlueprintFilesystem.
type BlueprintFilesystem struct {
	// Minsize size with data units
	Minsize    Minsize `json:"minsize"`
	Mountpoint string  `json:"mountpoint"`
}

// BlueprintFirewall Firewalld configuration
type BlueprintFirewall struct {
	// Ports List of ports (or port ranges) and protocols to open
	Ports *[]string `json:"ports,omitempty"`

	// Services Firewalld services to enable or disable
	Services *FirewallServices `json:"services,omitempty"`
	Zones    *[]FirewallZones  `json:"zones,omitempty"`
}

// BlueprintOpenSCAP defines model for BlueprintOpenSCAP.
type BlueprintOpenSCAP struct {
	Datastream    *string                `json:"datastream,omitempty"`
	JsonTailoring *OpenSCAPJSONTailoring `json:"json_tailoring,omitempty"`

	// PolicyId Puts a specified policy ID in the RHSM facts, so that any instances registered to
	// insights will be automatically connected to the compliance policy in the console.
	PolicyId  *openapi_types.UUID `json:"policy_id,omitempty"`
	ProfileId string              `json:"profile_id"`
	Tailoring *OpenSCAPTailoring  `json:"tailoring,omitempty"`
}

// BlueprintRepository defines model for BlueprintRepository.
type BlueprintRepository struct {
	Baseurls   *[]string `json:"baseurls,omitempty"`
	Enabled    *bool     `json:"enabled,omitempty"`
	Filename   *string   `json:"filename,omitempty"`
	Gpgcheck   *bool     `json:"gpgcheck,omitempty"`
	Gpgkeys    *[]string `json:"gpgkeys,omitempty"`
	Id         string    `json:"id"`
	Metalink   *string   `json:"metalink,omitempty"`
	Mirrorlist *string   `json:"mirrorlist,omitempty"`

	// ModuleHotfixes Disables modularity filtering for this repository.
	ModuleHotfixes *bool   `json:"module_hotfixes,omitempty"`
	Name           *string `json:"name,omitempty"`
	Priority       *int    `json:"priority,omitempty"`
	RepoGpgcheck   *bool   `json:"repo_gpgcheck,omitempty"`
	Sslverify      *bool   `json:"sslverify,omitempty"`
}

// BlueprintUser defines model for BlueprintUser.
type BlueprintUser struct {
	Description *string `json:"description,omitempty"`

	// Gid Group id to use instead of the default
	Gid *int `json:"gid,omitempty"`

	// Groups A list of additional groups to add the user to
	Groups *[]string `json:"groups,omitempty"`

	// Home The user's home directory
	Home *string `json:"home,omitempty"`

	// Key ssh public key
	Key  *string `json:"key,omitempty"`
	Name string  `json:"name"`

	// Password If the password starts with $6$, $5$, or $2b$ it will be stored as
	// an encrypted password. Otherwise it will be treated as a plain text
	// password.
	Password *string `json:"password,omitempty"`

	// Shell Login shell to use
	Shell *string `json:"shell,omitempty"`

	// Uid User id to use instead of the default
	Uid *int `json:"uid,omitempty"`
}

// Bootc defines model for Bootc.
type Bootc struct {
	Reference string `json:"reference"`
}

// BtrfsSubvolume defines model for BtrfsSubvolume.
type BtrfsSubvolume struct {
	// Mountpoint Mountpoint for the subvolume
	Mountpoint string `json:"mountpoint"`

	// Name The name of the subvolume, which defines the location (path) on the root volume
	Name string `json:"name"`
}

// BtrfsVolume defines model for BtrfsVolume.
type BtrfsVolume struct {
	// Minsize size with data units
	Minsize *Minsize `json:"minsize,omitempty"`

	// PartType The partition type GUID for GPT partitions. For DOS partitions, this field can be used to set the (2 hex digit) partition type. If not set, the type will be automatically set based on the mountpoint or the payload type.
	PartType   *string          `json:"part_type,omitempty"`
	Subvolumes []BtrfsSubvolume `json:"subvolumes"`
	Type       BtrfsVolumeType  `json:"type"`
}

// BtrfsVolumeType defines model for BtrfsVolume.Type.
type BtrfsVolumeType string

// CACertsCustomization defines model for CACertsCustomization.
type CACertsCustomization struct {
	PemCerts []string `json:"pem_certs"`
}

// CloneComposeBody defines model for CloneComposeBody.
type CloneComposeBody struct {
	union json.RawMessage
}

// CloneComposeResponse defines model for CloneComposeResponse.
type CloneComposeResponse struct {
	Href string             `json:"href"`
	Id   openapi_types.UUID `json:"id"`
	Kind string             `json:"kind"`
}

// CloneStatus defines model for CloneStatus.
type CloneStatus struct {
	Href    string              `json:"href"`
	Id      string              `json:"id"`
	Kind    string              `json:"kind"`
	Options CloneStatus_Options `json:"options"`
	Status  UploadStatusValue   `json:"status"`
	Type    UploadTypes         `json:"type"`
}

// CloneStatus_Options defines model for CloneStatus.Options.
type CloneStatus_Options struct {
	union json.RawMessage
}

// ComposeDeleteStatus defines model for ComposeDeleteStatus.
type ComposeDeleteStatus = ObjectReference

// ComposeId defines model for ComposeId.
type ComposeId struct {
	Href string             `json:"href"`
	Id   openapi_types.UUID `json:"id"`
	Kind string             `json:"kind"`
}

// ComposeList defines model for ComposeList.
type ComposeList struct {
	Items []ComposeStatus `json:"items"`
	Kind  string          `json:"kind"`
	Page  int             `json:"page"`
	Size  int             `json:"size"`
	Total int             `json:"total"`
}

// ComposeLogs defines model for ComposeLogs.
type ComposeLogs struct {
	Href        string        `json:"href"`
	Id          string        `json:"id"`
	ImageBuilds []interface{} `json:"image_builds"`
	Kind        string        `json:"kind"`
	Koji        *KojiLogs     `json:"koji,omitempty"`
}

// ComposeManifests defines model for ComposeManifests.
type ComposeManifests struct {
	Href      string        `json:"href"`
	Id        string        `json:"id"`
	Kind      string        `json:"kind"`
	Manifests []interface{} `json:"manifests"`
}

// ComposeMetadata defines model for ComposeMetadata.
type ComposeMetadata struct {
	Href string `json:"href"`
	Id   string `json:"id"`
	Kind string `json:"kind"`

	// OstreeCommit ID (hash) of the built commit
	OstreeCommit *string `json:"ostree_commit,omitempty"`

	// Packages Package list including NEVRA
	Packages *[]PackageMetadata `json:"packages,omitempty"`
	Request  *ComposeRequest    `json:"request,omitempty"`
}

// ComposeRequest defines model for ComposeRequest.
type ComposeRequest struct {
	Blueprint      *Blueprint      `json:"blueprint,omitempty"`
	Bootc          *Bootc          `json:"bootc,omitempty"`
	Customizations *Customizations `json:"customizations,omitempty"`
	Distribution   *string         `json:"distribution,omitempty"`
	ImageRequest   *ImageRequest   `json:"image_request,omitempty"`
	ImageRequests  *[]ImageRequest `json:"image_requests,omitempty"`
	Koji           *Koji           `json:"koji,omitempty"`
}

// ComposeSBOMs defines model for ComposeSBOMs.
type ComposeSBOMs struct {
	Href string `json:"href"`
	Id   string `json:"id"`

	// Items The SBOM documents for each image built in the compose.
	Items [][]ImageSBOM `json:"items"`
	Kind  string        `json:"kind"`
}

// ComposeStatus defines model for ComposeStatus.
type ComposeStatus struct {
	Href          string             `json:"href"`
	Id            string             `json:"id"`
	ImageStatus   ImageStatus        `json:"image_status"`
	ImageStatuses *[]ImageStatus     `json:"image_statuses,omitempty"`
	Kind          string             `json:"kind"`
	KojiStatus    *KojiStatus        `json:"koji_status,omitempty"`
	Status        ComposeStatusValue `json:"status"`
}

// ComposeStatusError defines model for ComposeStatusError.
type ComposeStatusError struct {
	Details interface{} `json:"details,omitempty"`
	Id      int         `json:"id"`
	Reason  string      `json:"reason"`
}

// ComposeStatusValue defines model for ComposeStatusValue.
type ComposeStatusValue string

// Container defines model for Container.
type Container struct {
	// Name Name to use for the container from the image
	Name *string `json:"name,omitempty"`

	// Source Reference to the container to embed
	Source string `json:"source"`

	// TlsVerify Control TLS verifification
	TlsVerify *bool `json:"tls_verify,omitempty"`
}

// ContainerUploadOptions defines model for ContainerUploadOptions.
type ContainerUploadOptions struct {
	// Name Name for the created container image
	Name *string `json:"name,omitempty"`

	// Tag Tag for the created container image
	Tag *string `json:"tag,omitempty"`
}

// ContainerUploadStatus defines model for ContainerUploadStatus.
type ContainerUploadStatus struct {
	// Digest Digest of the manifest of the uploaded container on the registry
	Digest string `json:"digest"`

	// Url FQDN of the uploaded image
	Url string `json:"url"`
}

// CustomRepository defines model for CustomRepository.
type CustomRepository struct {
	Baseurl        *[]string `json:"baseurl,omitempty"`
	CheckGpg       *bool     `json:"check_gpg,omitempty"`
	CheckRepoGpg   *bool     `json:"check_repo_gpg,omitempty"`
	Enabled        *bool     `json:"enabled,omitempty"`
	Filename       *string   `json:"filename,omitempty"`
	Gpgkey         *[]string `json:"gpgkey,omitempty"`
	Id             string    `json:"id"`
	Metalink       *string   `json:"metalink,omitempty"`
	Mirrorlist     *string   `json:"mirrorlist,omitempty"`
	ModuleHotfixes *bool     `json:"module_hotfixes,omitempty"`
	Name           *string   `json:"name,omitempty"`
	Priority       *int      `json:"priority,omitempty"`
	SslVerify      *bool     `json:"ssl_verify,omitempty"`
}

// Customizations defines model for Customizations.
type Customizations struct {
	Cacerts    *CACertsCustomization `json:"cacerts,omitempty"`
	Containers *[]Container          `json:"containers,omitempty"`

	// CustomRepositories Extra repositories for packages specified in customizations. These
	// repositories will be used to depsolve and retrieve packages. Additionally,
	// these packages will be saved and imported to the `/etc/yum.repos.d/` directory
	// on the image
	CustomRepositories *[]CustomRepository `json:"custom_repositories,omitempty"`
	Directories        *[]Directory        `json:"directories,omitempty"`
	Disk               *Disk               `json:"disk,omitempty"`
	DNF                *DNF                `json:"dnf,omitempty"`
	EnabledModules     *[]Module           `json:"enabled_modules,omitempty"`

	// Fdo FIDO device onboard configuration
	Fdo        *FDO          `json:"fdo,omitempty"`
	Files      *[]File       `json:"files,omitempty"`
	Filesystem *[]Filesystem `json:"filesystem,omitempty"`

	// Fips System FIPS mode setup
	Fips *FIPS `json:"fips,omitempty"`

	// Firewall Firewalld configuration
	Firewall *FirewallCustomization `json:"firewall,omitempty"`

	// Groups List of groups to create
	Groups *[]Group `json:"groups,omitempty"`

	// Hostname Configures the hostname
	Hostname *string `json:"hostname,omitempty"`

	// Ignition Ignition configuration
	Ignition *Ignition `json:"ignition,omitempty"`

	// InstallationDevice Name of the installation device, currently only useful for the edge-simplified-installer type
	InstallationDevice *string    `json:"installation_device,omitempty"`
	Installer          *Installer `json:"installer,omitempty"`
	Kernel             *Kernel    `json:"kernel,omitempty"`

	// Locale Locale configuration
	Locale   *Locale   `json:"locale,omitempty"`
	Openscap *OpenSCAP `json:"openscap,omitempty"`
	Packages *[]string `json:"packages,omitempty"`

	// PartitioningMode Select how the disk image will be partitioned. 'auto-lvm' will use raw unless
	// there are one or more mountpoints in which case it will use LVM. 'lvm' always
	// uses LVM, even when there are no extra mountpoints. 'raw' uses raw partitions
	// even when there are one or more mountpoints.
	PartitioningMode *CustomizationsPartitioningMode `json:"partitioning_mode,omitempty"`

	// PayloadRepositories Extra repositories for packages specified in customizations. These
	// repositories will only be used to depsolve and retrieve packages
	// for the OS itself (they will not be available for the build root or
	// any other part of the build process). The package_sets field for these
	// repositories is ignored.
	PayloadRepositories *[]Repository      `json:"payload_repositories,omitempty"`
	Rhsm                *RHSMCustomization `json:"rhsm,omitempty"`
	Rpm                 *RPMCustomization  `json:"rpm,omitempty"`
	Services            *Services          `json:"services,omitempty"`
	Subscription        *Subscription      `json:"subscription,omitempty"`

	// Timezone Timezone configuration
	Timezone *Timezone `json:"timezone,omitempty"`
	Users    *[]User   `json:"users,omitempty"`
}

// CustomizationsPartitioningMode Select how the disk image will be partitioned. 'auto-lvm' will use raw unless
// there are one or more mountpoints in which case it will use LVM. 'lvm' always
// uses LVM, even when there are no extra mountpoints. 'raw' uses raw partitions
// even when there are one or more mountpoints.
type CustomizationsPartitioningMode string

// DNF defines model for DNF.
type DNF struct {
	Config *DNFConfig `json:"config,omitempty"`
}

// DNFConfig defines model for DNFConfig.
type DNFConfig struct {
	// SetReleasever Set the releasever DNF variable, tying the system to a specific release of RHEL
	SetReleasever *bool `json:"set_releasever,omitempty"`
}

// DNFPluginConfig defines model for DNFPluginConfig.
type DNFPluginConfig struct {
	Enabled *bool `json:"enabled,omitempty"`
}

// DepsolveRequest defines model for DepsolveRequest.
type DepsolveRequest struct {
	Architecture string        `json:"architecture"`
	Blueprint    Blueprint     `json:"blueprint"`
	Distribution string        `json:"distribution"`
	ImageType    *ImageTypes   `json:"image_type,omitempty"`
	Repositories *[]Repository `json:"repositories,omitempty"`
}

// DepsolveResponse defines model for DepsolveResponse.
type DepsolveResponse struct {
	// Packages Package list including NEVRA
	Packages []PackageMetadataCommon `json:"packages"`
}

// Directory A custom directory to create in the final artifact.
type Directory struct {
	// EnsureParents Ensure that the parent directories exist
	EnsureParents *bool `json:"ensure_parents,omitempty"`

	// Group Group of the directory as a group name or a gid
	Group *Directory_Group `json:"group,omitempty"`

	// Mode Permissions string for the directory in octal format
	Mode *string `json:"mode,omitempty"`

	// Path Path to the directory
	Path string `json:"path"`

	// User Owner of the directory as a user name or a uid
	User *Directory_User `json:"user,omitempty"`
}

// DirectoryGroup0 defines model for .
type DirectoryGroup0 = string

// DirectoryGroup1 defines model for .
type DirectoryGroup1 = int64

// Directory_Group Group of the directory as a group name or a gid
type Directory_Group struct {
	union json.RawMessage
}

// DirectoryUser0 defines model for .
type DirectoryUser0 = string

// DirectoryUser1 defines model for .
type DirectoryUser1 = int64

// Directory_User Owner of the directory as a user name or a uid
type Directory_User struct {
	union json.RawMessage
}

// Disk defines model for Disk.
type Disk struct {
	// Minsize size with data units
	Minsize    *Minsize    `json:"minsize,omitempty"`
	Partitions []Partition `json:"partitions"`

	// Type Type of the partition table
	Type *DiskType `json:"type,omitempty"`
}

// DiskType Type of the partition table
type DiskType string

// DistributionDetails defines model for DistributionDetails.
type DistributionDetails struct {
	// Architectures Map of architecture names to their details
	Architectures *map[string]ArchitectureInfo `json:"architectures,omitempty"`

	// Codename Codename of the distribution
	Codename *string `json:"codename,omitempty"`
	Href     string  `json:"href"`
	Id       string  `json:"id"`
	Kind     string  `json:"kind"`

	// ModulePlatformId Module platform ID for DNF modularity
	ModulePlatformId *string `json:"module_platform_id,omitempty"`

	// Name Name of the distribution
	Name string `json:"name"`

	// OsVersion Full OS version including minor version
	OsVersion *string `json:"os_version,omitempty"`

	// OstreeRef Default OSTree reference template
	OstreeRef *string `json:"ostree_ref,omitempty"`

	// Product Product name
	Product *string `json:"product,omitempty"`

	// Releasever Release version used in repo files
	Releasever *string `json:"releasever,omitempty"`
}

// DistributionList Map of distributions to their architecture.
type DistributionList map[string]map[string][]BlueprintRepository

// Error defines model for Error.
type Error struct {
	Code        string      `json:"code"`
	Details     interface{} `json:"details,omitempty"`
	Href        string      `json:"href"`
	Id          string      `json:"id"`
	Kind        string      `json:"kind"`
	OperationId string      `json:"operation_id"`
	Reason      string      `json:"reason"`
}

// ErrorList defines model for ErrorList.
type ErrorList struct {
	Items []Error `json:"items"`
	Kind  string  `json:"kind"`
	Page  int     `json:"page"`
	Size  int     `json:"size"`
	Total int     `json:"total"`
}

// FDO FIDO device onboard configuration
type FDO struct {
	DiMfgStringTypeMacIface *string `json:"di_mfg_string_type_mac_iface,omitempty"`
	DiunPubKeyHash          *string `json:"diun_pub_key_hash,omitempty"`
	DiunPubKeyInsecure      *string `json:"diun_pub_key_insecure,omitempty"`
	DiunPubKeyRootCerts     *string `json:"diun_pub_key_root_certs,omitempty"`
	ManufacturingServerUrl  *string `json:"manufacturing_server_url,omitempty"`
}

// FIPS System FIPS mode setup
type FIPS struct {
	// Enabled Enables the system FIPS mode
	Enabled *bool `json:"enabled,omitempty"`
}

// File A custom file to create in the final artifact.
type File struct {
	// Data Contents of the file as plain text
	Data *string `json:"data,omitempty"`

	// EnsureParents Ensure that the parent directories exist
	EnsureParents *bool `json:"ensure_parents,omitempty"`

	// Group Group of the file as a gid or a group name
	Group *File_Group `json:"group,omitempty"`

	// Mode Permissions string for the file in octal format
	Mode *string `json:"mode,omitempty"`

	// Path Path to the file
	Path string `json:"path"`

	// User Owner of the file as a uid or a user name
	User *File_User `json:"user,omitempty"`
}

// FileGroup0 defines model for .
type FileGroup0 = string

// FileGroup1 defines model for .
type FileGroup1 = int64

// File_Group Group of the file as a gid or a group name
type File_Group struct {
	union json.RawMessage
}

// FileUser0 defines model for .
type FileUser0 = string

// FileUser1 defines model for .
type FileUser1 = int64

// File_User Owner of the file as a uid or a user name
type File_User struct {
	union json.RawMessage
}

// Filesystem defines model for Filesystem.
type Filesystem struct {
	// MinSize size of the filesystem in bytes
	MinSize    uint64 `json:"min_size"`
	Mountpoint string `json:"mountpoint"`
}

// FilesystemTyped defines model for FilesystemTyped.
type FilesystemTyped struct {
	// FsType The filesystem type. Swap partitions must have an empty mountpoint.
	FsType FilesystemTypedFsType `json:"fs_type"`
	Label  *string               `json:"label,omitempty"`

	// Minsize size with data units
	Minsize    *Minsize `json:"minsize,omitempty"`
	Mountpoint *string  `json:"mountpoint,omitempty"`

	// PartType The partition type GUID for GPT partitions. For DOS partitions, this field can be used to set the (2 hex digit) partition type. If not set, the type will be automatically set based on the mountpoint or the payload type.
	PartType *string              `json:"part_type,omitempty"`
	Type     *FilesystemTypedType `json:"type,omitempty"`
}

// FilesystemTypedFsType The filesystem type. Swap partitions must have an empty mountpoint.
type FilesystemTypedFsType string

// FilesystemTypedType defines model for FilesystemTyped.Type.
type FilesystemTypedType string

// FirewallCustomization Firewalld configuration
type FirewallCustomization struct {
	// Ports List of ports (or port ranges) and protocols to open
	Ports *[]string `json:"ports,omitempty"`

	// Services Firewalld services to enable or disable
	Services *FirewallServices `json:"services,omitempty"`
}

// FirewallServices Firewalld services to enable or disable
type FirewallServices struct {
	// Disabled List of services to disable
	Disabled *[]string `json:"disabled,omitempty"`

	// Enabled List of services to enable
	Enabled *[]string `json:"enabled,omitempty"`
}

// FirewallZones Bind a list of network sources to a zone to restrict traffic from
// those sources based on the settings of the zone.
type FirewallZones struct {
	// Name name of the zone, if left empty the sources will apply to
	// the default zone.
	Name *string `json:"name,omitempty"`

	// Sources List of sources for the zone
	Sources *[]string `json:"sources,omitempty"`
}

// GCPUploadOptions defines model for GCPUploadOptions.
type GCPUploadOptions struct {
	// Bucket Name of an existing STANDARD Storage class Bucket.
	Bucket *string `json:"bucket,omitempty"`

	// ImageName The name to use for the imported and shared Compute Engine image.
	// The image name must be unique within the GCP project, which is used
	// for the OS image upload and import. If not specified a random
	// 'composer-api-<uuid>' string is used as the image name.
	ImageName *string `json:"image_name,omitempty"`

	// Region The GCP region where the OS image will be imported to and shared from.
	// The value must be a valid GCP location. See https://cloud.google.com/storage/docs/locations.
	// If not specified, the multi-region location closest to the source
	// (source Storage Bucket location) is chosen automatically.
	Region string `json:"region"`

	// ShareWithAccounts List of valid Google accounts to share the imported Compute Engine image with.
	// Each string must contain a specifier of the account type. Valid formats are:
	//   - 'user:{emailid}': An email address that represents a specific
	//     Google account. For example, 'alice@example.com'.
	//   - 'serviceAccount:{emailid}': An email address that represents a
	//     service account. For example, 'my-other-app@appspot.gserviceaccount.com'.
	//   - 'group:{emailid}': An email address that represents a Google group.
	//     For example, 'admins@example.com'.
	//   - 'domain:{domain}': The G Suite domain (primary) that represents all
	//     the users of that domain. For example, 'google.com' or 'example.com'.
	// If not specified, the imported Compute Engine image is not shared with any
	// account.
	ShareWithAccounts *[]string `json:"share_with_accounts,omitempty"`
}

// GCPUploadStatus defines model for GCPUploadStatus.
type GCPUploadStatus struct {
	ImageName string `json:"image_name"`
	ProjectId string `json:"project_id"`
}

// Group defines model for Group.
type Group struct {
	// Gid Group id of the group to create (optional)
	Gid *int `json:"gid,omitempty"`

	// Name Name of the group to create
	Name string `json:"name"`
}

// Ignition Ignition configuration
type Ignition struct {
	Embedded  *IgnitionEmbedded  `json:"embedded,omitempty"`
	Firstboot *IgnitionFirstboot `json:"firstboot,omitempty"`
}

// IgnitionEmbedded defines model for IgnitionEmbedded.
type IgnitionEmbedded struct {
	Config string `json:"config"`
}

// IgnitionFirstboot defines model for IgnitionFirstboot.
type IgnitionFirstboot struct {
	// Url Provisioning URL
	Url string `json:"url"`
}

// ImageRequest defines model for ImageRequest.
type ImageRequest struct {
	Architecture string       `json:"architecture"`
	ImageType    ImageTypes   `json:"image_type"`
	Ostree       *OSTree      `json:"ostree,omitempty"`
	Repositories []Repository `json:"repositories"`

	// Size Size of image, in bytes. When set to 0 the image size is a minimum
	// defined by the image type.
	Size *uint64 `json:"size,omitempty"`

	// UploadOptions Options for a given upload destination.
	// This should really be oneOf but AWSS3UploadOptions is a subset of
	// AWSEC2UploadOptions. This means that all AWSEC2UploadOptions objects
	// are also valid AWSS3UploadOptionas objects which violates the oneOf
	// rules. Therefore, we have to use anyOf here but be aware that it isn't
	// possible to mix and match more schemas together.
	UploadOptions *UploadOptions `json:"upload_options,omitempty"`

	// UploadTargets The type and options for multiple upload targets. Each item defines
	// a separate upload destination with its own options. Multiple
	// different targets as well as multiple targets of the same kind are
	// supported.
	UploadTargets *[]UploadTarget `json:"upload_targets,omitempty"`
}

// ImageSBOM defines model for ImageSBOM.
type ImageSBOM struct {
	// PipelineName The name of the osbuild pipeline which has the packages described
	// in the SBOM installed.
	PipelineName string `json:"pipeline_name"`

	// PipelinePurpose The purpose of the pipeline. The `buildroot` pipeline was used for
	// the build environment dueing the image build. The `image` pipeline
	// represents the actual content of the image. Due to the nature of
	// some image types, there may be multiple pipelines of the same
	// purpose.
	PipelinePurpose ImageSBOMPipelinePurpose `json:"pipeline_purpose"`

	// Sbom The SBOM document in the 'sbom_type' format.
	Sbom interface{} `json:"sbom"`

	// SbomType The type of the SBOM document. Currently only SPDX is supported.
	SbomType ImageSBOMSbomType `json:"sbom_type"`
}

// ImageSBOMPipelinePurpose The purpose of the pipeline. The `buildroot` pipeline was used for
// the build environment dueing the image build. The `image` pipeline
// represents the actual content of the image. Due to the nature of
// some image types, there may be multiple pipelines of the same
// purpose.
type ImageSBOMPipelinePurpose string

// ImageSBOMSbomType The type of the SBOM document. Currently only SPDX is supported.
type ImageSBOMSbomType string

// ImageStatus defines model for ImageStatus.
type ImageStatus struct {
	Error          *ComposeStatusError `json:"error,omitempty"`
	Progress       *Progress           `json:"progress,omitempty"`
	Status         ImageStatusValue    `json:"status"`
	UploadStatus   *UploadStatus       `json:"upload_status,omitempty"`
	UploadStatuses *[]UploadStatus     `json:"upload_statuses,omitempty"`
}

// ImageStatusValue defines model for ImageStatusValue.
type ImageStatusValue string

// ImageTypeInfo Image type metadata from images library
type ImageTypeInfo struct {
	// Aliases Alternative names for this image type
	Aliases            *[]string `json:"aliases,omitempty"`
	BasePartitionTable *Disk     `json:"base_partition_table,omitempty"`

	// BootMode Boot mode for the image
	BootMode *ImageTypeInfoBootMode `json:"boot_mode,omitempty"`

	// DefaultSize Default image size in bytes
	DefaultSize *uint64 `json:"default_size,omitempty"`

	// Exports Names of stages that produce the build output
	Exports *[]string `json:"exports,omitempty"`

	// Filename Canonical filename for the image
	Filename *string `json:"filename,omitempty"`

	// IsoLabel ISO label (only for ISO image types)
	IsoLabel *string `json:"iso_label"`

	// MimeType MIME type of the image
	MimeType *string `json:"mime_type,omitempty"`

	// Name Image type name
	Name string `json:"name"`

	// OstreeRef Default OSTree ref for this image type
	OstreeRef *string `json:"ostree_ref,omitempty"`

	// PartitionType Partition table type
	PartitionType *ImageTypeInfoPartitionType `json:"partition_type,omitempty"`

	// PayloadPackageSets Package set names safe for custom packages via custom repos
	PayloadPackageSets *[]string `json:"payload_package_sets,omitempty"`

	// RequiredBlueprintOptions Customization options required by this image type
	RequiredBlueprintOptions *[]string `json:"required_blueprint_options,omitempty"`

	// SupportedBlueprintOptions Customization options supported by this image type
	SupportedBlueprintOptions *[]string `json:"supported_blueprint_options,omitempty"`
}

// ImageTypeInfoBootMode Boot mode for the image
type ImageTypeInfoBootMode string

// ImageTypeInfoPartitionType Partition table type
type ImageTypeInfoPartitionType string

// ImageTypes defines model for ImageTypes.
type ImageTypes string

// ImportKeys defines model for ImportKeys.
type ImportKeys struct {
	Files *[]string `json:"files,omitempty"`
}

// Installer defines model for Installer.
type Installer struct {
	SudoNopasswd *[]string `json:"sudo-nopasswd,omitempty"`
	Unattended   *bool     `json:"unattended,omitempty"`
}

// Kernel defines model for Kernel.
type Kernel struct {
	// Append Appends arguments to the bootloader kernel command line
	Append *string `json:"append,omitempty"`

	// Name Name of the kernel to use
	Name *string `json:"name,omitempty"`
}

// Koji defines model for Koji.
type Koji struct {
	Name    string `json:"name"`
	Release string `json:"release"`
	Server  string `json:"server"`
	TaskId  int    `json:"task_id"`
	Version string `json:"version"`
}

// KojiLogs defines model for KojiLogs.
type KojiLogs struct {
	Import interface{} `json:"import"`
	Init   interface{} `json:"init"`
}

// KojiStatus defines model for KojiStatus.
type KojiStatus struct {
	BuildId *int `json:"build_id,omitempty"`
}

// List defines model for List.
type List struct {
	Kind  string `json:"kind"`
	Page  int    `json:"page"`
	Size  int    `json:"size"`
	Total int    `json:"total"`
}

// LocalUploadOptions defines model for LocalUploadOptions.
type LocalUploadOptions = map[string]interface{}

// LocalUploadStatus defines model for LocalUploadStatus.
type LocalUploadStatus struct {
	ArtifactPath string `json:"artifact_path"`
}

// Locale Locale configuration
type Locale struct {
	// Keyboard Sets the keyboard layout
	Keyboard *string `json:"keyboard,omitempty"`

	// Languages List of locales to be installed, the first one becomes primary, subsequent ones are secondary
	Languages *[]string `json:"languages,omitempty"`
}

// LogicalVolume defines model for LogicalVolume.
type LogicalVolume struct {
	// FsType The filesystem type for the logical volume. Swap LVs must have an empty mountpoint.
	FsType LogicalVolumeFsType `json:"fs_type"`
	Label  *string             `json:"label,omitempty"`

	// Minsize size with data units
	Minsize *Minsize `json:"minsize,omitempty"`

	// Mountpoint Mountpoint for the logical volume
	Mountpoint *string `json:"mountpoint,omitempty"`
	Name       *string `json:"name,omitempty"`
}

// LogicalVolumeFsType The filesystem type for the logical volume. Swap LVs must have an empty mountpoint.
type LogicalVolumeFsType string

// Module defines model for Module.
type Module struct {
	// Name Name of the module to enable.
	Name string `json:"name"`

	// Stream Stream to enable.
	Stream string `json:"stream"`
}

// OCIUploadOptions defines model for OCIUploadOptions.
type OCIUploadOptions = map[string]interface{}

// OCIUploadStatus defines model for OCIUploadStatus.
type OCIUploadStatus struct {
	Url string `json:"url"`
}

// OSTree defines model for OSTree.
type OSTree struct {
	// Contenturl A URL which, if set, is used for fetching content. Implies that `url` is set as well,
	// which will be used for metadata only.
	Contenturl *string `json:"contenturl,omitempty"`

	// Parent Can be either a commit (example: 02604b2da6e954bd34b8b82a835e5a77d2b60ffa), or a branch-like reference (example: rhel/8/x86_64/edge)
	Parent *string `json:"parent,omitempty"`
	Ref    *string `json:"ref,omitempty"`

	// Rhsm Determines whether a valid subscription manager (candlepin) identity is required to
	// access this repository. Consumer certificates will be used as client certificates when
	// fetching metadata and content.
	Rhsm *bool   `json:"rhsm,omitempty"`
	Url  *string `json:"url,omitempty"`
}

// ObjectReference defines model for ObjectReference.
type ObjectReference struct {
	Href string `json:"href"`
	Id   string `json:"id"`
	Kind string `json:"kind"`
}

// OpenSCAP defines model for OpenSCAP.
type OpenSCAP struct {
	JsonTailoring *OpenSCAPJSONTailoring `json:"json_tailoring,omitempty"`

	// PolicyId Puts a specified policy ID in the RHSM facts, so that any instances registered to
	// insights will be automatically connected to the compliance policy in the console.
	PolicyId  *openapi_types.UUID `json:"policy_id,omitempty"`
	ProfileId string              `json:"profile_id"`
	Tailoring *OpenSCAPTailoring  `json:"tailoring,omitempty"`
}

// OpenSCAPJSONTailoring defines model for OpenSCAPJSONTailoring.
type OpenSCAPJSONTailoring struct {
	Filepath  string `json:"filepath"`
	ProfileId string `json:"profile_id"`
}

// OpenSCAPTailoring defines model for OpenSCAPTailoring.
type OpenSCAPTailoring struct {
	Selected   *[]string `json:"selected,omitempty"`
	Unselected *[]string `json:"unselected,omitempty"`
}

// Package defines model for Package.
type Package struct {
	// Name Name of the package to install. File globbing is supported,
	// eg. 'openssh-*'
	Name string `json:"name"`

	// Version Optional version of the package to install. If left blank the
	// latest available version will be used. Wildcards are supported
	// eg. '4.11.*'
	Version *string `json:"version,omitempty"`
}

// PackageDetails defines model for PackageDetails.
type PackageDetails struct {
	Arch        string  `json:"arch"`
	Buildtime   *string `json:"buildtime,omitempty"`
	Description *string `json:"description,omitempty"`
	Epoch       *string `json:"epoch,omitempty"`
	License     *string `json:"license,omitempty"`
	Name        string  `json:"name"`
	Release     string  `json:"release"`
	Summary     *string `json:"summary,omitempty"`
	Url         *string `json:"url,omitempty"`
	Version     string  `json:"version"`
}

// PackageGroup defines model for PackageGroup.
type PackageGroup struct {
	// Name Package group name
	Name string `json:"name"`
}

// PackageMetadata defines model for PackageMetadata.
type PackageMetadata struct {
	Arch string `json:"arch"`

	// Checksum Optional package checksum using ALGO:HASH form
	Checksum  *string `json:"checksum,omitempty"`
	Epoch     *string `json:"epoch,omitempty"`
	Name      string  `json:"name"`
	Release   string  `json:"release"`
	Sigmd5    string  `json:"sigmd5"`
	Signature *string `json:"signature,omitempty"`
	Type      string  `json:"type"`
	Version   string  `json:"version"`
}

// PackageMetadataCommon defines model for PackageMetadataCommon.
type PackageMetadataCommon struct {
	Arch string `json:"arch"`

	// Checksum Optional package checksum using ALGO:HASH form
	Checksum  *string `json:"checksum,omitempty"`
	Epoch     *string `json:"epoch,omitempty"`
	Name      string  `json:"name"`
	Release   string  `json:"release"`
	Signature *string `json:"signature,omitempty"`
	Type      string  `json:"type"`
	Version   string  `json:"version"`
}

// Partition defines model for Partition.
type Partition struct {
	union json.RawMessage
}

// Progress defines model for Progress.
type Progress struct {
	// Done Amount of completed steps in the build.
	Done        int          `json:"done"`
	SubProgress *SubProgress `json:"subprogress,omitempty"`

	// Total Total amount of steps in the build.
	Total int `json:"total"`
}

// PulpOSTreeUploadOptions defines model for PulpOSTreeUploadOptions.
type PulpOSTreeUploadOptions struct {
	// Basepath Basepath for distributing the repository
	Basepath string `json:"basepath"`

	// Repository Repository to import the ostree commit to
	Repository    *string `json:"repository,omitempty"`
	ServerAddress *string `json:"server_address,omitempty"`
}

// PulpOSTreeUploadStatus defines model for PulpOSTreeUploadStatus.
type PulpOSTreeUploadStatus struct {
	RepoUrl string `json:"repo_url"`
}

// RHSMConfig defines model for RHSMConfig.
type RHSMConfig struct {
	DnfPlugins          *SubManDNFPluginsConfig `json:"dnf_plugins,omitempty"`
	SubscriptionManager *SubManConfig           `json:"subscription_manager,omitempty"`
}

// RHSMCustomization defines model for RHSMCustomization.
type RHSMCustomization struct {
	Config *RHSMConfig `json:"config,omitempty"`
}

// RPMCustomization defines model for RPMCustomization.
type RPMCustomization struct {
	ImportKeys *ImportKeys `json:"import_keys,omitempty"`
}

// Repository Repository configuration.
// At least one of the 'baseurl', 'mirrorlist', 'metalink' properties must
// be specified. If more of them are specified, the order of precedence is
// the same as listed above.
type Repository struct {
	Baseurl  *string `json:"baseurl,omitempty"`
	CheckGpg *bool   `json:"check_gpg,omitempty"`

	// CheckRepoGpg Enables gpg verification of the repository metadata
	CheckRepoGpg *bool `json:"check_repo_gpg,omitempty"`

	// Gpgkey GPG key used to sign packages in this repository.
	Gpgkey     *string `json:"gpgkey,omitempty"`
	IgnoreSsl  *bool   `json:"ignore_ssl,omitempty"`
	Metalink   *string `json:"metalink,omitempty"`
	Mirrorlist *string `json:"mirrorlist,omitempty"`

	// ModuleHotfixes Disables modularity filtering for this repository.
	ModuleHotfixes *bool `json:"module_hotfixes,omitempty"`

	// PackageSets Naming package sets for a repository assigns it to a specific part
	// (pipeline) of the build process.
	PackageSets *[]string `json:"package_sets,omitempty"`

	// Rhsm Determines whether a valid subscription is required to access this repository.
	Rhsm *bool `json:"rhsm,omitempty"`
}

// SSHKey defines model for SSHKey.
type SSHKey struct {
	// Key Adds the key to the user's authorized_keys file
	Key string `json:"key"`

	// User User to configure the ssh key for
	User string `json:"user"`
}

// SearchPackagesRequest defines model for SearchPackagesRequest.
type SearchPackagesRequest struct {
	Architecture string `json:"architecture"`
	Distribution string `json:"distribution"`

	// Packages Array of package names to search for. Supports * wildcards for
	// names, but not for versions.
	Packages     []string      `json:"packages"`
	Repositories *[]Repository `json:"repositories,omitempty"`
}

// SearchPackagesResponse defines model for SearchPackagesResponse.
type SearchPackagesResponse struct {
	// Packages Detailed package information from DNF
	Packages []PackageDetails `json:"packages"`
}

// Services defines model for Services.
type Services struct {
	// Disabled List of services to disable by default
	Disabled *[]string `json:"disabled,omitempty"`

	// Enabled List of services to enable by default
	Enabled *[]string `json:"enabled,omitempty"`

	// Masked List of services to mask by default
	Masked *[]string `json:"masked,omitempty"`
}

// SubManConfig defines model for SubManConfig.
type SubManConfig struct {
	Rhsm      *SubManRHSMConfig      `json:"rhsm,omitempty"`
	Rhsmcertd *SubManRHSMCertdConfig `json:"rhsmcertd,omitempty"`
}

// SubManDNFPluginsConfig defines model for SubManDNFPluginsConfig.
type SubManDNFPluginsConfig struct {
	ProductId           *DNFPluginConfig `json:"product_id,omitempty"`
	SubscriptionManager *DNFPluginConfig `json:"subscription_manager,omitempty"`
}

// SubManRHSMCertdConfig defines model for SubManRHSMCertdConfig.
type SubManRHSMCertdConfig struct {
	AutoRegistration *bool `json:"auto_registration,omitempty"`
}

// SubManRHSMConfig defines model for SubManRHSMConfig.
type SubManRHSMConfig struct {
	AutoEnableYumPlugins *bool `json:"auto_enable_yum_plugins,omitempty"`
	ManageRepos          *bool `json:"manage_repos,omitempty"`
}

// SubProgress defines model for SubProgress.
type SubProgress struct {
	// Done Amount of completed steps in the build.
	Done int `json:"done"`

	// Total Total amount of steps in the build.
	Total int `json:"total"`
}

// Subscription defines model for Subscription.
type Subscription struct {
	ActivationKey string `json:"activation_key"`
	BaseUrl       string `json:"base_url"`
	Insights      bool   `json:"insights"`

	// InsightsClientProxy Optional value to set proxy option when registering the system to Insights
	InsightsClientProxy *string `json:"insights_client_proxy,omitempty"`
	Organization        string  `json:"organization"`

	// PatchUrl Optional value used to specify the patch host when registering the system with Insights.
	PatchUrl *string `json:"patch_url,omitempty"`

	// Rhc Optional flag to use rhc to register the system, which also always enables Insights.
	Rhc       *bool  `json:"rhc,omitempty"`
	ServerUrl string `json:"server_url"`

	// TemplateName Optional value to register with a template when using rhc to register the system with Insights.
	TemplateName *string `json:"template_name,omitempty"`

	// TemplateUuid Optional value to register with a template when registering the system with Insights.
	TemplateUuid *string `json:"template_uuid,omitempty"`
}

// Timezone Timezone configuration
type Timezone struct {
	// Ntpservers List of ntp servers
	Ntpservers *[]string `json:"ntpservers,omitempty"`

	// Timezone Name of the timezone, defaults to UTC
	Timezone *string `json:"timezone,omitempty"`
}

// UploadOptions Options for a given upload destination.
// This should really be oneOf but AWSS3UploadOptions is a subset of
// AWSEC2UploadOptions. This means that all AWSEC2UploadOptions objects
// are also valid AWSS3UploadOptionas objects which violates the oneOf
// rules. Therefore, we have to use anyOf here but be aware that it isn't
// possible to mix and match more schemas together.
type UploadOptions struct {
	union json.RawMessage
}

// UploadStatus defines model for UploadStatus.
type UploadStatus struct {
	Options UploadStatus_Options `json:"options"`
	Status  UploadStatusValue    `json:"status"`
	Type    UploadTypes          `json:"type"`
}

// UploadStatus_Options defines model for UploadStatus.Options.
type UploadStatus_Options struct {
	union json.RawMessage
}

// UploadStatusValue defines model for UploadStatusValue.
type UploadStatusValue string

// UploadTarget defines model for UploadTarget.
type UploadTarget struct {
	Type UploadTypes `json:"type"`

	// UploadOptions Options for a given upload destination.
	// This should really be oneOf but AWSS3UploadOptions is a subset of
	// AWSEC2UploadOptions. This means that all AWSEC2UploadOptions objects
	// are also valid AWSS3UploadOptionas objects which violates the oneOf
	// rules. Therefore, we have to use anyOf here but be aware that it isn't
	// possible to mix and match more schemas together.
	UploadOptions UploadOptions `json:"upload_options"`
}

// UploadTypes defines model for UploadTypes.
type UploadTypes string

// User defines model for User.
type User struct {
	Groups *[]string `json:"groups,omitempty"`
	Key    *string   `json:"key,omitempty"`
	Name   string    `json:"name"`

	// Password If the password starts with $6$, $5$, or $2b$ it will be stored as
	// an encrypted password. Otherwise it will be treated as a plain text
	// password.
	Password *string `json:"password,omitempty"`
}

// VolumeGroup defines model for VolumeGroup.
type VolumeGroup struct {
	LogicalVolumes []LogicalVolume `json:"logical_volumes"`

	// Minsize size with data units
	Minsize *Minsize `json:"minsize,omitempty"`

	// Name Volume group name (will be automatically generated if omitted)
	Name *string `json:"name,omitempty"`

	// PartType The partition type GUID for GPT partitions. For DOS partitions, this field can be used to set the (2 hex digit) partition type. If not set, the type will be automatically set based on the mountpoint or the payload type.
	PartType *string         `json:"part_type,omitempty"`
	Type     VolumeGroupType `json:"type"`
}

// VolumeGroupType defines model for VolumeGroup.Type.
type VolumeGroupType string

// Minsize size with data units
type Minsize = string

// Page defines model for page.
type Page = string

// Size defines model for size.
type Size = string

// GetDistributionParams defines parameters for GetDistribution.
type GetDistributionParams struct {
	// ImageType Filter by image type. Multiple values can be specified.
	ImageType *[]string `form:"image_type,omitempty" json:"image_type,omitempty"`

	// Architecture Filter by architecture. Multiple values can be specified.
	Architecture *[]string `form:"architecture,omitempty" json:"architecture,omitempty"`
}

// GetErrorListParams defines parameters for GetErrorList.
type GetErrorListParams struct {
	// Page Page index
	Page *Page `form:"page,omitempty" json:"page,omitempty"`

	// Size Number of items in each page
	Size *Size `form:"size,omitempty" json:"size,omitempty"`
}

// PostComposeJSONRequestBody defines body for PostCompose for application/json ContentType.
type PostComposeJSONRequestBody = ComposeRequest

// PostCloneComposeJSONRequestBody defines body for PostCloneCompose for application/json ContentType.
type PostCloneComposeJSONRequestBody = CloneComposeBody

// PostDepsolveBlueprintJSONRequestBody defines body for PostDepsolveBlueprint for application/json ContentType.
type PostDepsolveBlueprintJSONRequestBody = DepsolveRequest

// PostSearchPackagesJSONRequestBody defines body for PostSearchPackages for application/json ContentType.
type PostSearchPackagesJSONRequestBody = SearchPackagesRequest

// AsBlueprintFileGroup0 returns the union data inside the BlueprintFile_Group as a BlueprintFileGroup0
func (t BlueprintFile_Group) AsBlueprintFileGroup0() (BlueprintFileGroup0, error) {
	var body BlueprintFileGroup0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBlueprintFileGroup0 overwrites any union data inside the BlueprintFile_Group as the provided BlueprintFileGroup0
func (t *BlueprintFile_Group) FromBlueprintFileGroup0(v BlueprintFileGroup0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBlueprintFileGroup0 performs a merge with any union data inside the BlueprintFile_Group, using the provided BlueprintFileGroup0
func (t *BlueprintFile_Group) MergeBlueprintFileGroup0(v BlueprintFileGroup0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBlueprintFileGroup1 returns the union data inside the BlueprintFile_Group as a BlueprintFileGroup1
func (t BlueprintFile_Group) AsBlueprintFileGroup1() (BlueprintFileGroup1, error) {
	var body BlueprintFileGroup1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBlueprintFileGroup1 overwrites any union data inside the BlueprintFile_Group as the provided BlueprintFileGroup1
func (t *BlueprintFile_Group) FromBlueprintFileGroup1(v BlueprintFileGroup1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBlueprintFileGroup1 performs a merge with any union data inside the BlueprintFile_Group, using the provided BlueprintFileGroup1
func (t *BlueprintFile_Group) MergeBlueprintFileGroup1(v BlueprintFileGroup1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t BlueprintFile_Group) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *BlueprintFile_Group) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsBlueprintFileUser0 returns the union data inside the BlueprintFile_User as a BlueprintFileUser0
func (t BlueprintFile_User) AsBlueprintFileUser0() (BlueprintFileUser0, error) {
	var body BlueprintFileUser0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBlueprintFileUser0 overwrites any union data inside the BlueprintFile_User as the provided BlueprintFileUser0
func (t *BlueprintFile_User) FromBlueprintFileUser0(v BlueprintFileUser0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBlueprintFileUser0 performs a merge with any union data inside the BlueprintFile_User, using the provided BlueprintFileUser0
func (t *BlueprintFile_User) MergeBlueprintFileUser0(v BlueprintFileUser0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBlueprintFileUser1 returns the union data inside the BlueprintFile_User as a BlueprintFileUser1
func (t BlueprintFile_User) AsBlueprintFileUser1() (BlueprintFileUser1, error) {
	var body BlueprintFileUser1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBlueprintFileUser1 overwrites any union data inside the BlueprintFile_User as the provided BlueprintFileUser1
func (t *BlueprintFile_User) FromBlueprintFileUser1(v BlueprintFileUser1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBlueprintFileUser1 performs a merge with any union data inside the BlueprintFile_User, using the provided BlueprintFileUser1
func (t *BlueprintFile_User) MergeBlueprintFileUser1(v BlueprintFileUser1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t BlueprintFile_User) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *BlueprintFile_User) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsAWSEC2CloneCompose returns the union data inside the CloneComposeBody as a AWSEC2CloneCompose
func (t CloneComposeBody) AsAWSEC2CloneCompose() (AWSEC2CloneCompose, error) {
	var body AWSEC2CloneCompose
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSEC2CloneCompose overwrites any union data inside the CloneComposeBody as the provided AWSEC2CloneCompose
func (t *CloneComposeBody) FromAWSEC2CloneCompose(v AWSEC2CloneCompose) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSEC2CloneCompose performs a merge with any union data inside the CloneComposeBody, using the provided AWSEC2CloneCompose
func (t *CloneComposeBody) MergeAWSEC2CloneCompose(v AWSEC2CloneCompose) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t CloneComposeBody) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CloneComposeBody) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsAWSEC2UploadStatus returns the union data inside the CloneStatus_Options as a AWSEC2UploadStatus
func (t CloneStatus_Options) AsAWSEC2UploadStatus() (AWSEC2UploadStatus, error) {
	var body AWSEC2UploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSEC2UploadStatus overwrites any union data inside the CloneStatus_Options as the provided AWSEC2UploadStatus
func (t *CloneStatus_Options) FromAWSEC2UploadStatus(v AWSEC2UploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSEC2UploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided AWSEC2UploadStatus
func (t *CloneStatus_Options) MergeAWSEC2UploadStatus(v AWSEC2UploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAWSS3UploadStatus returns the union data inside the CloneStatus_Options as a AWSS3UploadStatus
func (t CloneStatus_Options) AsAWSS3UploadStatus() (AWSS3UploadStatus, error) {
	var body AWSS3UploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSS3UploadStatus overwrites any union data inside the CloneStatus_Options as the provided AWSS3UploadStatus
func (t *CloneStatus_Options) FromAWSS3UploadStatus(v AWSS3UploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSS3UploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided AWSS3UploadStatus
func (t *CloneStatus_Options) MergeAWSS3UploadStatus(v AWSS3UploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGCPUploadStatus returns the union data inside the CloneStatus_Options as a GCPUploadStatus
func (t CloneStatus_Options) AsGCPUploadStatus() (GCPUploadStatus, error) {
	var body GCPUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGCPUploadStatus overwrites any union data inside the CloneStatus_Options as the provided GCPUploadStatus
func (t *CloneStatus_Options) FromGCPUploadStatus(v GCPUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGCPUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided GCPUploadStatus
func (t *CloneStatus_Options) MergeGCPUploadStatus(v GCPUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAzureUploadStatus returns the union data inside the CloneStatus_Options as a AzureUploadStatus
func (t CloneStatus_Options) AsAzureUploadStatus() (AzureUploadStatus, error) {
	var body AzureUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAzureUploadStatus overwrites any union data inside the CloneStatus_Options as the provided AzureUploadStatus
func (t *CloneStatus_Options) FromAzureUploadStatus(v AzureUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAzureUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided AzureUploadStatus
func (t *CloneStatus_Options) MergeAzureUploadStatus(v AzureUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsContainerUploadStatus returns the union data inside the CloneStatus_Options as a ContainerUploadStatus
func (t CloneStatus_Options) AsContainerUploadStatus() (ContainerUploadStatus, error) {
	var body ContainerUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromContainerUploadStatus overwrites any union data inside the CloneStatus_Options as the provided ContainerUploadStatus
func (t *CloneStatus_Options) FromContainerUploadStatus(v ContainerUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeContainerUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided ContainerUploadStatus
func (t *CloneStatus_Options) MergeContainerUploadStatus(v ContainerUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOCIUploadStatus returns the union data inside the CloneStatus_Options as a OCIUploadStatus
func (t CloneStatus_Options) AsOCIUploadStatus() (OCIUploadStatus, error) {
	var body OCIUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOCIUploadStatus overwrites any union data inside the CloneStatus_Options as the provided OCIUploadStatus
func (t *CloneStatus_Options) FromOCIUploadStatus(v OCIUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOCIUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided OCIUploadStatus
func (t *CloneStatus_Options) MergeOCIUploadStatus(v OCIUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPulpOSTreeUploadStatus returns the union data inside the CloneStatus_Options as a PulpOSTreeUploadStatus
func (t CloneStatus_Options) AsPulpOSTreeUploadStatus() (PulpOSTreeUploadStatus, error) {
	var body PulpOSTreeUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPulpOSTreeUploadStatus overwrites any union data inside the CloneStatus_Options as the provided PulpOSTreeUploadStatus
func (t *CloneStatus_Options) FromPulpOSTreeUploadStatus(v PulpOSTreeUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePulpOSTreeUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided PulpOSTreeUploadStatus
func (t *CloneStatus_Options) MergePulpOSTreeUploadStatus(v PulpOSTreeUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsLocalUploadStatus returns the union data inside the CloneStatus_Options as a LocalUploadStatus
func (t CloneStatus_Options) AsLocalUploadStatus() (LocalUploadStatus, error) {
	var body LocalUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromLocalUploadStatus overwrites any union data inside the CloneStatus_Options as the provided LocalUploadStatus
func (t *CloneStatus_Options) FromLocalUploadStatus(v LocalUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeLocalUploadStatus performs a merge with any union data inside the CloneStatus_Options, using the provided LocalUploadStatus
func (t *CloneStatus_Options) MergeLocalUploadStatus(v LocalUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t CloneStatus_Options) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CloneStatus_Options) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDirectoryGroup0 returns the union data inside the Directory_Group as a DirectoryGroup0
func (t Directory_Group) AsDirectoryGroup0() (DirectoryGroup0, error) {
	var body DirectoryGroup0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDirectoryGroup0 overwrites any union data inside the Directory_Group as the provided DirectoryGroup0
func (t *Directory_Group) FromDirectoryGroup0(v DirectoryGroup0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDirectoryGroup0 performs a merge with any union data inside the Directory_Group, using the provided DirectoryGroup0
func (t *Directory_Group) MergeDirectoryGroup0(v DirectoryGroup0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDirectoryGroup1 returns the union data inside the Directory_Group as a DirectoryGroup1
func (t Directory_Group) AsDirectoryGroup1() (DirectoryGroup1, error) {
	var body DirectoryGroup1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDirectoryGroup1 overwrites any union data inside the Directory_Group as the provided DirectoryGroup1
func (t *Directory_Group) FromDirectoryGroup1(v DirectoryGroup1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDirectoryGroup1 performs a merge with any union data inside the Directory_Group, using the provided DirectoryGroup1
func (t *Directory_Group) MergeDirectoryGroup1(v DirectoryGroup1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Directory_Group) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Directory_Group) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDirectoryUser0 returns the union data inside the Directory_User as a DirectoryUser0
func (t Directory_User) AsDirectoryUser0() (DirectoryUser0, error) {
	var body DirectoryUser0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDirectoryUser0 overwrites any union data inside the Directory_User as the provided DirectoryUser0
func (t *Directory_User) FromDirectoryUser0(v DirectoryUser0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDirectoryUser0 performs a merge with any union data inside the Directory_User, using the provided DirectoryUser0
func (t *Directory_User) MergeDirectoryUser0(v DirectoryUser0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDirectoryUser1 returns the union data inside the Directory_User as a DirectoryUser1
func (t Directory_User) AsDirectoryUser1() (DirectoryUser1, error) {
	var body DirectoryUser1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDirectoryUser1 overwrites any union data inside the Directory_User as the provided DirectoryUser1
func (t *Directory_User) FromDirectoryUser1(v DirectoryUser1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDirectoryUser1 performs a merge with any union data inside the Directory_User, using the provided DirectoryUser1
func (t *Directory_User) MergeDirectoryUser1(v DirectoryUser1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Directory_User) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Directory_User) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsFileGroup0 returns the union data inside the File_Group as a FileGroup0
func (t File_Group) AsFileGroup0() (FileGroup0, error) {
	var body FileGroup0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFileGroup0 overwrites any union data inside the File_Group as the provided FileGroup0
func (t *File_Group) FromFileGroup0(v FileGroup0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFileGroup0 performs a merge with any union data inside the File_Group, using the provided FileGroup0
func (t *File_Group) MergeFileGroup0(v FileGroup0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFileGroup1 returns the union data inside the File_Group as a FileGroup1
func (t File_Group) AsFileGroup1() (FileGroup1, error) {
	var body FileGroup1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFileGroup1 overwrites any union data inside the File_Group as the provided FileGroup1
func (t *File_Group) FromFileGroup1(v FileGroup1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFileGroup1 performs a merge with any union data inside the File_Group, using the provided FileGroup1
func (t *File_Group) MergeFileGroup1(v FileGroup1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t File_Group) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *File_Group) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsFileUser0 returns the union data inside the File_User as a FileUser0
func (t File_User) AsFileUser0() (FileUser0, error) {
	var body FileUser0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFileUser0 overwrites any union data inside the File_User as the provided FileUser0
func (t *File_User) FromFileUser0(v FileUser0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFileUser0 performs a merge with any union data inside the File_User, using the provided FileUser0
func (t *File_User) MergeFileUser0(v FileUser0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFileUser1 returns the union data inside the File_User as a FileUser1
func (t File_User) AsFileUser1() (FileUser1, error) {
	var body FileUser1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFileUser1 overwrites any union data inside the File_User as the provided FileUser1
func (t *File_User) FromFileUser1(v FileUser1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFileUser1 performs a merge with any union data inside the File_User, using the provided FileUser1
func (t *File_User) MergeFileUser1(v FileUser1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t File_User) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *File_User) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsFilesystemTyped returns the union data inside the Partition as a FilesystemTyped
func (t Partition) AsFilesystemTyped() (FilesystemTyped, error) {
	var body FilesystemTyped
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFilesystemTyped overwrites any union data inside the Partition as the provided FilesystemTyped
func (t *Partition) FromFilesystemTyped(v FilesystemTyped) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFilesystemTyped performs a merge with any union data inside the Partition, using the provided FilesystemTyped
func (t *Partition) MergeFilesystemTyped(v FilesystemTyped) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBtrfsVolume returns the union data inside the Partition as a BtrfsVolume
func (t Partition) AsBtrfsVolume() (BtrfsVolume, error) {
	var body BtrfsVolume
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBtrfsVolume overwrites any union data inside the Partition as the provided BtrfsVolume
func (t *Partition) FromBtrfsVolume(v BtrfsVolume) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBtrfsVolume performs a merge with any union data inside the Partition, using the provided BtrfsVolume
func (t *Partition) MergeBtrfsVolume(v BtrfsVolume) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsVolumeGroup returns the union data inside the Partition as a VolumeGroup
func (t Partition) AsVolumeGroup() (VolumeGroup, error) {
	var body VolumeGroup
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromVolumeGroup overwrites any union data inside the Partition as the provided VolumeGroup
func (t *Partition) FromVolumeGroup(v VolumeGroup) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeVolumeGroup performs a merge with any union data inside the Partition, using the provided VolumeGroup
func (t *Partition) MergeVolumeGroup(v VolumeGroup) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Partition) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Partition) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsAWSEC2UploadOptions returns the union data inside the UploadOptions as a AWSEC2UploadOptions
func (t UploadOptions) AsAWSEC2UploadOptions() (AWSEC2UploadOptions, error) {
	var body AWSEC2UploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSEC2UploadOptions overwrites any union data inside the UploadOptions as the provided AWSEC2UploadOptions
func (t *UploadOptions) FromAWSEC2UploadOptions(v AWSEC2UploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSEC2UploadOptions performs a merge with any union data inside the UploadOptions, using the provided AWSEC2UploadOptions
func (t *UploadOptions) MergeAWSEC2UploadOptions(v AWSEC2UploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAWSS3UploadOptions returns the union data inside the UploadOptions as a AWSS3UploadOptions
func (t UploadOptions) AsAWSS3UploadOptions() (AWSS3UploadOptions, error) {
	var body AWSS3UploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSS3UploadOptions overwrites any union data inside the UploadOptions as the provided AWSS3UploadOptions
func (t *UploadOptions) FromAWSS3UploadOptions(v AWSS3UploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSS3UploadOptions performs a merge with any union data inside the UploadOptions, using the provided AWSS3UploadOptions
func (t *UploadOptions) MergeAWSS3UploadOptions(v AWSS3UploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGCPUploadOptions returns the union data inside the UploadOptions as a GCPUploadOptions
func (t UploadOptions) AsGCPUploadOptions() (GCPUploadOptions, error) {
	var body GCPUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGCPUploadOptions overwrites any union data inside the UploadOptions as the provided GCPUploadOptions
func (t *UploadOptions) FromGCPUploadOptions(v GCPUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGCPUploadOptions performs a merge with any union data inside the UploadOptions, using the provided GCPUploadOptions
func (t *UploadOptions) MergeGCPUploadOptions(v GCPUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAzureUploadOptions returns the union data inside the UploadOptions as a AzureUploadOptions
func (t UploadOptions) AsAzureUploadOptions() (AzureUploadOptions, error) {
	var body AzureUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAzureUploadOptions overwrites any union data inside the UploadOptions as the provided AzureUploadOptions
func (t *UploadOptions) FromAzureUploadOptions(v AzureUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAzureUploadOptions performs a merge with any union data inside the UploadOptions, using the provided AzureUploadOptions
func (t *UploadOptions) MergeAzureUploadOptions(v AzureUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsContainerUploadOptions returns the union data inside the UploadOptions as a ContainerUploadOptions
func (t UploadOptions) AsContainerUploadOptions() (ContainerUploadOptions, error) {
	var body ContainerUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromContainerUploadOptions overwrites any union data inside the UploadOptions as the provided ContainerUploadOptions
func (t *UploadOptions) FromContainerUploadOptions(v ContainerUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeContainerUploadOptions performs a merge with any union data inside the UploadOptions, using the provided ContainerUploadOptions
func (t *UploadOptions) MergeContainerUploadOptions(v ContainerUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsLocalUploadOptions returns the union data inside the UploadOptions as a LocalUploadOptions
func (t UploadOptions) AsLocalUploadOptions() (LocalUploadOptions, error) {
	var body LocalUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromLocalUploadOptions overwrites any union data inside the UploadOptions as the provided LocalUploadOptions
func (t *UploadOptions) FromLocalUploadOptions(v LocalUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeLocalUploadOptions performs a merge with any union data inside the UploadOptions, using the provided LocalUploadOptions
func (t *UploadOptions) MergeLocalUploadOptions(v LocalUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOCIUploadOptions returns the union data inside the UploadOptions as a OCIUploadOptions
func (t UploadOptions) AsOCIUploadOptions() (OCIUploadOptions, error) {
	var body OCIUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOCIUploadOptions overwrites any union data inside the UploadOptions as the provided OCIUploadOptions
func (t *UploadOptions) FromOCIUploadOptions(v OCIUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOCIUploadOptions performs a merge with any union data inside the UploadOptions, using the provided OCIUploadOptions
func (t *UploadOptions) MergeOCIUploadOptions(v OCIUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPulpOSTreeUploadOptions returns the union data inside the UploadOptions as a PulpOSTreeUploadOptions
func (t UploadOptions) AsPulpOSTreeUploadOptions() (PulpOSTreeUploadOptions, error) {
	var body PulpOSTreeUploadOptions
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPulpOSTreeUploadOptions overwrites any union data inside the UploadOptions as the provided PulpOSTreeUploadOptions
func (t *UploadOptions) FromPulpOSTreeUploadOptions(v PulpOSTreeUploadOptions) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePulpOSTreeUploadOptions performs a merge with any union data inside the UploadOptions, using the provided PulpOSTreeUploadOptions
func (t *UploadOptions) MergePulpOSTreeUploadOptions(v PulpOSTreeUploadOptions) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t UploadOptions) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *UploadOptions) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsAWSEC2UploadStatus returns the union data inside the UploadStatus_Options as a AWSEC2UploadStatus
func (t UploadStatus_Options) AsAWSEC2UploadStatus() (AWSEC2UploadStatus, error) {
	var body AWSEC2UploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSEC2UploadStatus overwrites any union data inside the UploadStatus_Options as the provided AWSEC2UploadStatus
func (t *UploadStatus_Options) FromAWSEC2UploadStatus(v AWSEC2UploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSEC2UploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided AWSEC2UploadStatus
func (t *UploadStatus_Options) MergeAWSEC2UploadStatus(v AWSEC2UploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAWSS3UploadStatus returns the union data inside the UploadStatus_Options as a AWSS3UploadStatus
func (t UploadStatus_Options) AsAWSS3UploadStatus() (AWSS3UploadStatus, error) {
	var body AWSS3UploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAWSS3UploadStatus overwrites any union data inside the UploadStatus_Options as the provided AWSS3UploadStatus
func (t *UploadStatus_Options) FromAWSS3UploadStatus(v AWSS3UploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAWSS3UploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided AWSS3UploadStatus
func (t *UploadStatus_Options) MergeAWSS3UploadStatus(v AWSS3UploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsGCPUploadStatus returns the union data inside the UploadStatus_Options as a GCPUploadStatus
func (t UploadStatus_Options) AsGCPUploadStatus() (GCPUploadStatus, error) {
	var body GCPUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromGCPUploadStatus overwrites any union data inside the UploadStatus_Options as the provided GCPUploadStatus
func (t *UploadStatus_Options) FromGCPUploadStatus(v GCPUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeGCPUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided GCPUploadStatus
func (t *UploadStatus_Options) MergeGCPUploadStatus(v GCPUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAzureUploadStatus returns the union data inside the UploadStatus_Options as a AzureUploadStatus
func (t UploadStatus_Options) AsAzureUploadStatus() (AzureUploadStatus, error) {
	var body AzureUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAzureUploadStatus overwrites any union data inside the UploadStatus_Options as the provided AzureUploadStatus
func (t *UploadStatus_Options) FromAzureUploadStatus(v AzureUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAzureUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided AzureUploadStatus
func (t *UploadStatus_Options) MergeAzureUploadStatus(v AzureUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsContainerUploadStatus returns the union data inside the UploadStatus_Options as a ContainerUploadStatus
func (t UploadStatus_Options) AsContainerUploadStatus() (ContainerUploadStatus, error) {
	var body ContainerUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromContainerUploadStatus overwrites any union data inside the UploadStatus_Options as the provided ContainerUploadStatus
func (t *UploadStatus_Options) FromContainerUploadStatus(v ContainerUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeContainerUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided ContainerUploadStatus
func (t *UploadStatus_Options) MergeContainerUploadStatus(v ContainerUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsOCIUploadStatus returns the union data inside the UploadStatus_Options as a OCIUploadStatus
func (t UploadStatus_Options) AsOCIUploadStatus() (OCIUploadStatus, error) {
	var body OCIUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromOCIUploadStatus overwrites any union data inside the UploadStatus_Options as the provided OCIUploadStatus
func (t *UploadStatus_Options) FromOCIUploadStatus(v OCIUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeOCIUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided OCIUploadStatus
func (t *UploadStatus_Options) MergeOCIUploadStatus(v OCIUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPulpOSTreeUploadStatus returns the union data inside the UploadStatus_Options as a PulpOSTreeUploadStatus
func (t UploadStatus_Options) AsPulpOSTreeUploadStatus() (PulpOSTreeUploadStatus, error) {
	var body PulpOSTreeUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPulpOSTreeUploadStatus overwrites any union data inside the UploadStatus_Options as the provided PulpOSTreeUploadStatus
func (t *UploadStatus_Options) FromPulpOSTreeUploadStatus(v PulpOSTreeUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePulpOSTreeUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided PulpOSTreeUploadStatus
func (t *UploadStatus_Options) MergePulpOSTreeUploadStatus(v PulpOSTreeUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsLocalUploadStatus returns the union data inside the UploadStatus_Options as a LocalUploadStatus
func (t UploadStatus_Options) AsLocalUploadStatus() (LocalUploadStatus, error) {
	var body LocalUploadStatus
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromLocalUploadStatus overwrites any union data inside the UploadStatus_Options as the provided LocalUploadStatus
func (t *UploadStatus_Options) FromLocalUploadStatus(v LocalUploadStatus) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeLocalUploadStatus performs a merge with any union data inside the UploadStatus_Options, using the provided LocalUploadStatus
func (t *UploadStatus_Options) MergeLocalUploadStatus(v LocalUploadStatus) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t UploadStatus_Options) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *UploadStatus_Options) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// ServerInterface represents all server handlers.
type ServerInterface interface {
	// The status of a cloned compose
	// (GET /clones/{id})
	GetCloneStatus(ctx echo.Context, id openapi_types.UUID) error
	// Create compose
	// (POST /compose)
	PostCompose(ctx echo.Context) error
	// The list of composes
	// (GET /composes/)
	GetComposeList(ctx echo.Context) error
	// Delete a compose
	// (DELETE /composes/{id})
	DeleteCompose(ctx echo.Context, id openapi_types.UUID) error
	// The status of a compose
	// (GET /composes/{id})
	GetComposeStatus(ctx echo.Context, id openapi_types.UUID) error
	// Clone an existing compose
	// (POST /composes/{id}/clone)
	PostCloneCompose(ctx echo.Context, id openapi_types.UUID) error
	// Download the artifact for a compose.
	// (GET /composes/{id}/download)
	GetComposeDownload(ctx echo.Context, id openapi_types.UUID) error
	// Get logs for a compose.
	// (GET /composes/{id}/logs)
	GetComposeLogs(ctx echo.Context, id openapi_types.UUID) error
	// Get the manifests for a compose.
	// (GET /composes/{id}/manifests)
	GetComposeManifests(ctx echo.Context, id openapi_types.UUID) error
	// Get the metadata for a compose.
	// (GET /composes/{id}/metadata)
	GetComposeMetadata(ctx echo.Context, id openapi_types.UUID) error
	// Get the SBOMs for a compose.
	// (GET /composes/{id}/sboms)
	GetComposeSBOMs(ctx echo.Context, id openapi_types.UUID) error
	// Depsolve one or more blueprints
	// (POST /depsolve/blueprint)
	PostDepsolveBlueprint(ctx echo.Context) error
	// Get all of the supported distribution repository details
	// (GET /distributions)
	GetDistributionList(ctx echo.Context) error
	// Get details for a specific distribution
	// (GET /distributions/{distro})
	GetDistribution(ctx echo.Context, distro string, params GetDistributionParams) error
	// Get a list of all possible errors
	// (GET /errors)
	GetErrorList(ctx echo.Context, params GetErrorListParams) error
	// Get error description
	// (GET /errors/{id})
	GetError(ctx echo.Context, id string) error
	// Get the openapi spec in json format
	// (GET /openapi)
	GetOpenapi(ctx echo.Context) error
	// Search for detailed information on a list of package names
	// (POST /search/packages)
	PostSearchPackages(ctx echo.Context) error
}

// ServerInterfaceWrapper converts echo contexts to parameters.
type ServerInterfaceWrapper struct {
	Handler ServerInterface
}

// GetCloneStatus converts echo context to params.
func (w *ServerInterfaceWrapper) GetCloneStatus(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetCloneStatus(ctx, id)
	return err
}

// PostCompose converts echo context to params.
func (w *ServerInterfaceWrapper) PostCompose(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.PostCompose(ctx)
	return err
}

// GetComposeList converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeList(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeList(ctx)
	return err
}

// DeleteCompose converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteCompose(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteCompose(ctx, id)
	return err
}

// GetComposeStatus converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeStatus(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeStatus(ctx, id)
	return err
}

// PostCloneCompose converts echo context to params.
func (w *ServerInterfaceWrapper) PostCloneCompose(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.PostCloneCompose(ctx, id)
	return err
}

// GetComposeDownload converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeDownload(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeDownload(ctx, id)
	return err
}

// GetComposeLogs converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeLogs(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeLogs(ctx, id)
	return err
}

// GetComposeManifests converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeManifests(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeManifests(ctx, id)
	return err
}

// GetComposeMetadata converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeMetadata(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeMetadata(ctx, id)
	return err
}

// GetComposeSBOMs converts echo context to params.
func (w *ServerInterfaceWrapper) GetComposeSBOMs(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id openapi_types.UUID

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetComposeSBOMs(ctx, id)
	return err
}

// PostDepsolveBlueprint converts echo context to params.
func (w *ServerInterfaceWrapper) PostDepsolveBlueprint(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.PostDepsolveBlueprint(ctx)
	return err
}

// GetDistributionList converts echo context to params.
func (w *ServerInterfaceWrapper) GetDistributionList(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDistributionList(ctx)
	return err
}

// GetDistribution converts echo context to params.
func (w *ServerInterfaceWrapper) GetDistribution(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "distro" -------------
	var distro string

	err = runtime.BindStyledParameterWithOptions("simple", "distro", ctx.Param("distro"), &distro, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter distro: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Parameter object where we will unmarshal all parameters from the context
	var params GetDistributionParams
	// ------------- Optional query parameter "image_type" -------------

	err = runtime.BindQueryParameter("form", true, false, "image_type", ctx.QueryParams(), &params.ImageType)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter image_type: %s", err))
	}

	// ------------- Optional query parameter "architecture" -------------

	err = runtime.BindQueryParameter("form", true, false, "architecture", ctx.QueryParams(), &params.Architecture)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter architecture: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDistribution(ctx, distro, params)
	return err
}

// GetErrorList converts echo context to params.
func (w *ServerInterfaceWrapper) GetErrorList(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Parameter object where we will unmarshal all parameters from the context
	var params GetErrorListParams
	// ------------- Optional query parameter "page" -------------

	err = runtime.BindQueryParameter("form", true, false, "page", ctx.QueryParams(), &params.Page)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter page: %s", err))
	}

	// ------------- Optional query parameter "size" -------------

	err = runtime.BindQueryParameter("form", true, false, "size", ctx.QueryParams(), &params.Size)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter size: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetErrorList(ctx, params)
	return err
}

// GetError converts echo context to params.
func (w *ServerInterfaceWrapper) GetError(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "id" -------------
	var id string

	err = runtime.BindStyledParameterWithOptions("simple", "id", ctx.Param("id"), &id, runtime.BindStyledParameterOptions{ParamLocation: runtime.ParamLocationPath, Explode: false, Required: true})
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter id: %s", err))
	}

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetError(ctx, id)
	return err
}

// GetOpenapi converts echo context to params.
func (w *ServerInterfaceWrapper) GetOpenapi(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetOpenapi(ctx)
	return err
}

// PostSearchPackages converts echo context to params.
func (w *ServerInterfaceWrapper) PostSearchPackages(ctx echo.Context) error {
	var err error

	ctx.Set(BearerScopes, []string{})

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.PostSearchPackages(ctx)
	return err
}

// This is a simple interface which specifies echo.Route addition functions which
// are present on both echo.Echo and echo.Group, since we want to allow using
// either of them for path registration
type EchoRouter interface {
	CONNECT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	DELETE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	GET(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	HEAD(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	OPTIONS(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PATCH(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	POST(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PUT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	TRACE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
}

// RegisterHandlers adds each server route to the EchoRouter.
func RegisterHandlers(router EchoRouter, si ServerInterface) {
	RegisterHandlersWithBaseURL(router, si, "")
}

// Registers handlers, and prepends BaseURL to the paths, so that the paths
// can be served under a prefix.
func RegisterHandlersWithBaseURL(router EchoRouter, si ServerInterface, baseURL string) {

	wrapper := ServerInterfaceWrapper{
		Handler: si,
	}

	router.GET(baseURL+"/clones/:id", wrapper.GetCloneStatus)
	router.POST(baseURL+"/compose", wrapper.PostCompose)
	router.GET(baseURL+"/composes/", wrapper.GetComposeList)
	router.DELETE(baseURL+"/composes/:id", wrapper.DeleteCompose)
	router.GET(baseURL+"/composes/:id", wrapper.GetComposeStatus)
	router.POST(baseURL+"/composes/:id/clone", wrapper.PostCloneCompose)
	router.GET(baseURL+"/composes/:id/download", wrapper.GetComposeDownload)
	router.GET(baseURL+"/composes/:id/logs", wrapper.GetComposeLogs)
	router.GET(baseURL+"/composes/:id/manifests", wrapper.GetComposeManifests)
	router.GET(baseURL+"/composes/:id/metadata", wrapper.GetComposeMetadata)
	router.GET(baseURL+"/composes/:id/sboms", wrapper.GetComposeSBOMs)
	router.POST(baseURL+"/depsolve/blueprint", wrapper.PostDepsolveBlueprint)
	router.GET(baseURL+"/distributions", wrapper.GetDistributionList)
	router.GET(baseURL+"/distributions/:distro", wrapper.GetDistribution)
	router.GET(baseURL+"/errors", wrapper.GetErrorList)
	router.GET(baseURL+"/errors/:id", wrapper.GetError)
	router.GET(baseURL+"/openapi", wrapper.GetOpenapi)
	router.POST(baseURL+"/search/packages", wrapper.PostSearchPackages)

}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y993IbObY4/Coo/uYrj6+ZxKDgqq17KSpR2aKCpaVLC3aDJKRuoA2gSVFz/e5fIXQi",
	"0QyyPTuz13/sjsVGODgADk4+fxQc6geUICJ44eMfhQAy6COBmPlriOR/XcQdhgOBKSl8LFzCIQKYuOil",
	"UCygF+gHHso0H0MvRIWPhY3Ct2/FApZ9voaITQvFAoG+/KJaFgvcGSEfyi5iGsjfuWCYDFU3jl8tc5+H",
	"fh8xQAcAC+RzgAlA0BkBM2AammiAGJpqNRce1XYRPN+ij2ro1l13v11re5SgtkQfVxNB18USTOhdMhog",
	"JrAEZAA9joqFIPXTHwWGhmo9cxMVC3wEGXqcYDF6hI5DQ7MxZmWFj/8sbNTqjebm1vZOdaNW+FIsKExY",
	"xzI/QMbgVK2doa8hZsiVwxgYvsTNaP8JOUL20+u7CTwK3QuFev7mBcaAF1BYmiAuShuF4p+57GKBExjw",
	"ERWPerfTMPnTUvR1Hio7wuywLkNjV0AR6luSQRT0cRYi6ONS1dmuV7d26ltbzeZO0230bRhbE8Uzi5Hz",
	"FpecgW79e45AEPY97OgrPIChJ+J22SvdGQCOBBAUqM/gdzFCwHQB6vK+LwIIPEqGRUD7g5A7UCAX3Fyd",
	"9gjmgCERMoLcMugIDtBLgBmUQwMfD0cC9BHglBLEgBhBAgaUASpGiIFQra1HBGRDJHi5R3okgUWwEMlp",
	"+YgygZicDaQmA5C4PYKzE2IOJOwc+ghArqaSf6enA8lsyRb1KfUQJN+/qattZ95RDJlnJ8XpKWQj6/jM",
	"GWGBHBEy1CEDuvSwZA9BujvwkYAuFBAMGPUB9uEQceDhPoOKZmehVp8fJTwLDugfhd8YGhQ+Fv5fJXnv",
	"KoaiVzpyiOtpoAH/NgvbGQzUgyNbATkRkHSEq1MyQpgBFwmIPV6woCWiOAtWq5oUU/v9sr35uNlYutmq",
	"n3UrXkOGvufmjqYBYo/jxyEiSB/tzC0u3MqTmF1Re0QpR+q4354BhVBwJIe5BckoReDiwQAxRAQYIChX",
	"zwElQAEMoPzfGGIP9j3UIy4KEHExGcoWcty54fQdQiT0JToUULe1FEYSUqnPiH0vzuVtpQM1hb6jyNV7",
	"LQkK8EOuaEhI8NdQsj2q4RCPEQEMcRoyB4Eho2FQVuRDTiIJAfWxkFRKHWHZRW4d4kLSFAaJS31ACQJ9",
	"yJErVwjBzU1nD2DeI2aFyDULTD9WCjDba+BRJ7VT6QWemi/RIgNGx1guMgL/UYFfBJMRYnoL9VHnIxp6",
	"rlp8hBdIZLch5gIxBd8Rnch74GEuAPQ8EIHBP/bISIiAf6xUXOrwso8dRjkdiLJD/QoipZBXHA9XoNz7",
	"inlG/3uM0eQf6qeS4+GSBwXi4v/B1+idfZQTPcaTvFMolxBHP0nUEyoAD5CDBxi5RYCF/NFFbuhkNiQH",
	"D7NIl6QXhfJ+2B/hdN/Fpyt7XFZA9ywo1zR0ILkywxyqGW2sVNiPQXjE7jxQnT0JUrrZG4BpoKa73a85",
	"JdivNUqNxka9tFN1mqXNjVq9uom2qzuoZoNOIAKJWACXBEI3Wg0qcwQHmLhqr/UN1TTlkjIBvVXOYnQO",
	"BR6jkosZcgRl08ogJC70ERHQ43NfSyM6KQlaklOXNMgzSGo6W2jQ7G+WNpz6oNRwYbUEN2u1UrVf3azW",
	"6jvulru1lNAnGJvf27kTuORByHv7sxRyFZIzA2RqABsIu16IAoaJWPMpcigREBMjj868OdG3iEUQFCC/",
	"L8k30W+zPBTQA5CJAXQkgx/LDIvYgXhcmyzhhFxQH7/C+GFdNFS87Ha22yyPYRFiXMwFo/OrvpbcsfyG",
	"+6G6uoKCkKOY23S0QFoGnQHw0EAA5Adiqj6NKBc9ogcGE+x56ibx+bs9QC5lsFTfsV1gROQD7T761A2N",
	"qL0SWs9UextO1cnlNkWD8yyvvf4uF9qXLzAX0POQu+p2mlE0ubTMnlrHDJdGAPSwYeQDPQovShFAng5X",
	"/dyHzvMEMpcrvEMB+9jDYqrwuQ50NsCi2zi3AxEsuRj7XlzZoBkjxq38RQtw5I8RA6YFIEpHkzlQW+Wt",
	"8lb17Sxt3j1ak5hABzGx/P632rJZZip9IzXdxzbM7yUfJfIdhqCI2cWYDOF16FA05NS2HS7mz8sH4M+q",
	"LRksbXp+IFsOXLqs5cHehWqJrXfmQP78oxAQ77oc1YYEBcSUC+Rb2F7JktIBSNoAX7KQAcVEpEB8EzBm",
	"UitINkq2r2gmOOhcdoFPXWSV/QeYoQn0vDUgMR0iGpqPhYSErrfqXKop3xK7QNWmZICHSraLHh0j4s7L",
	"ZUOCowdwoYAetVPqW0XT1K18dNEYO0uEunQHoDsUgRMyKYZ6U0CJN5WP4CD04jcUuUNU4tgPPCVDlCI6",
	"ypT4P/NYVlw0rnAXWhcYdVy6wrjht2LhGTGClh6DE93KyH4eWtb+VLf6VizQABHuwGDlg3YRINJtty71",
	"48OE2gxMho/qLGd0AzAUtOSN/TkNQRd5yBFgJLl1zcI8G64+4kTikZFbBu+igd7p75LFYXACQuIhzntE",
	"KNEAMqTEaMqATxnK3HAspRrsjIADOZKSQTzO6e1ZGbxTY0NvAqe8R0KOuPy9CJCU7CcjpAiXmYJQgF4E",
	"g+nxy+Adg5N3QPWUkMXg8x6xDZIDZ1aLweCkUCxo/MWo/GIVPAPKcd5rdJX6Ki/9hGGB5D8qSDiVaeiX",
	"Vf+yW8lSaKP3OKcCSRRDIb/xCAlCMYsACtAPsecCgX1UXp3ViY9TDJ31ZWMj7i8b6uqoezb3PrNgeb/L",
	"+W4cMUkTloLfjdrJPnz0jKb55JbzEXhGU74qarrdoxNkxYbE8SslS2/3ddTuW7EQck1w7LDJr9/z/t1w",
	"m2T0bRHXpt5vC+OohSn1RC/jGfQ5y/JzLhTQLhZKyCP6r0aHHAQelCOjF2Gj1Dnvp3r/ZkeCYIhdeZeh",
	"UeXMqXAZVfYkStDFoPDxn/M8fPwLJgINFbf8UhrSUvLrZqPw7YsWT2w2WMR8zCW7zYEeNH68FJSYAOoI",
	"qJ40H4oMcNXNRsOGggCKkU2kECMQi9Nedp2KnPhT8/vciPaDeDEh2oSbxWkY4VT2+okonZE51Kq/LDu9",
	"CZeZPYI+JpGdedHliZqp/YxIf1bTUhlDtlRASnUuxnMvAT5hKtewx0TdXOAYdk7TyzkjHzUClZ3WqM/g",
	"dyk/UyYAg2SI+HulRg4YFdShniJFkiNJ7/Y/C7XaR+EEhWJhu2r+gX0YqH+uZ/tdkbpHC05TeUlPV9dv",
	"RCM8qF7rEciYwZo7YJLGccEQ9K3LfeKUPAqIPap+WQJiNM1x9+L8Ou4krz71sDO1KmUvQyFvZ6xQB7ot",
	"6OxFhFo+xkDSaF4EXBIKKAAkU814E0eyR7HJAAjaI/LcDkeCx5yf5HR8KLADPW8qTxxBSldvyI5ciYfl",
	"UNHkZmaHEk49w4MYSvexEIZKMTpP3xiV1Mascv7krIvFFAZnaUoy08LLmWKE5ja+DzkKmZc9fwm5iBTa",
	"jkvKDLkjqJXZjn78Ki7mosJGyNuubFe0QbEiR6S8Qnklgy2GrWr6mXtktH4pzGUkVw/laquGwdAZIefZ",
	"3nUYDBWjlF7lUmBydtBHAnqYPNsx5WPGKONlrdwMGJXbUaZsWIn6/bdkiv8RKT9rvbBarW1C5oz+EZtk",
	"l6FNT+JhLuaBiGGQn8sOIoJyNf9/M+QhyNE/tkv6qqdmhvL/Nxv6FwXfLuToorsKLEqx+TiiYoBf7Dor",
	"LjeVA9USMiym8j0WKMVPKJ+H6JTmeS3kayoZpnLY1MfodTYyzOPi48G5N0YMD6a2z7MmiCW37cZwI2to",
	"DJcp6Yc2iql5RuxGmnlJBxF0I44nkpWLFozkacJb2sJKByABPqXTga6r7deScxI0zdInR1A131jlro+o",
	"Ta9zbSZ4x4FsAGIzmG1Iq3QkpSLtFSSFowx3x/mohNxas7mxA1qtVqtdP3+F7Q3vYa+zcX6935S/dc7Z",
	"4ck+O7vHH87ObibhEbxqHftXp7TzejWofd2ruXvN1+ru9Utl88UG07x1Sy5nw84Kcz6hzGajNEZ00wBw",
	"AZl6ycQI/Lb5WxH81vytKPnY32r932KtQx8BLqh8/yDvEUgAIg6bBvKNi0YqgwsxQmyCU8qKPgJCyUSu",
	"ZpETEaZH4n7pO5n2p0Oa6Zt1BhhiAtRHczytfLvtWMvr85ZTvbKOn1LhzL+DDCmPEWdm676GcFrGtKLJ",
	"aKkvO2f++KhJ6c4KTlPRBFaoBBvwbtgfUy/Ux2dGAMiw8zOOQ/G3WDjj0Uj2XbNrVOXNIymNZjxI0Wi4",
	"XDTAxOhbY0+I36Vk8z7ynpHiE8if2rZJGVklFze3eYhZWzIKIBOPehIbBmL9mvbBOrzp7Cm0Hl5ep3Rv",
	"ZXBAGdi76KZ+K+p3bICRlGcgicye8igrd78RAr/XwAi9ABcPsXg/M5eypSqvEiSK2j9BQmDnXuWAsVeP",
	"bJsgEZhDEMCp9gWUY+dc32iLV5c/Zk6qTZdkcBspG/uyh0W7OOt/MFW+LymQbIfBajVb02MU+Y+xhS4l",
	"C5ZKpd39w845aO9fXXcOOu3W9X6pVOr1yFmn067utdutPh62Jp3d1rBz0ymXy70eKZVK++d7M12+w106",
	"Ac66+pQv+C511eOXqCoWbZvFl1zpfdK/XCEeUGK8zD1vhVEvFGRXMWn7Vpzz+HCzBHWjVkeN5uZWCW3v",
	"9EsbNbdego3mZqlR29xsNhuNarVaXS5lrcKSxatLnFHevqhF7TMuL3pajc895CGB8nxhRmpIy/nIETue",
	"MXGXO84qbKmmRT2D9Rhp+Druf9BO6yWdGpFotUWp1paVRFd3RT8eNXO0/0vutx5y8RrokP/QjVE+U8qW",
	"YhWADQhzekzEBtBBf3yz0fhn+oSXWg7pE1ZrsTtxGYAWouIMEjxAXPxQfPjpQb8fGbO603j0xSszzuc/",
	"cmFU8qLo0aG+j4XV7/H3EeSSWdMMntwBAUzz4hscgLS4iInjhcqF+nz/9qq1phNQjAibjU47M694A69M",
	"a4sONIX4q2TMhTwDoULLBcnWzjjlFQv92N3wy7dZLqOfdkVcyeIlV9yPpJOFPVSjtb0ELc6BKQe/LPFm",
	"I+SVtgu5Tu4r7ozy0I/3Zabz6iR2dpi3UiMdYRcR7N2Lsx9LZ6OlzAsVci7gUif0lclQyhMqnlB7Juh7",
	"GCubtWNl+hqtNGASMGDM6/vJDCEPldQwUnoBATwEuQBiQtVAvKi8BqJBtNUdkTFmlMjxlSEl1aJHoCNC",
	"6AGjBo5dYNS8q95/taly+nwZ4u1v6I/g+WyvKI/HXb60mCFId0Vrnvo8tkIf+hXhkWc/GWi1PhlE3qrg",
	"1tl9MANlF7jKvuwzRpnFCGUCnD7+McsFZ7S5kFvVpDZG2DSeA0CvJyWj8tBxEJdrGUDshUxKoiYwSC4o",
	"pUGMG85RxsShe25lC2KC5vyqI2/zOIIkNxhHe+Tb3HLMMU4sW9Ggke961uat7GZsWjY/KROPmvWjgEOr",
	"Ktfjj4nCfN4xglEPXJ92gWqDB9iJzLrxpCrwcZmq3SzQLsKYJX1PBNqCbYn3wyhGnWwUwIxzHuWKaFpR",
	"BYcWEg6Ha86gY5Ss8tEy3KRo4RomCTw07/usMUf+HlH8iNmdi2xLFhMpBs0Zs+uhTEzojHPAp71ze8jc",
	"DG4iJa0/NfFbFbMfHxdgbTbatBgt2XraFOu0gh31L2JGVaaux2EwtJu79OfILmZv812WWGOX+WVq/emm",
	"1h9mJeXce/xeG+i/M2wiG8L1oyKwHhc7wO4rd910m0wUT8qdBROQldbK4HqEOOqRTO90uJR8rF0UcOqN",
	"kQmJFQyjMYrHL4NWjF9vWlTuyjz5nBgF4dhE1WI/oCzl8/KvOU/dfyUW1x4xxDshuqvhdZZaWgNLMlEu",
	"f9VIlR8fhfaG2JcV/cJWCV5ZeajloScLR+hcdteJNYmc2uZudZ6nwl8q4CQdx/orDuVvG4eSDT9JVJ8p",
	"E2FAuRgybZpcnbn5Fcvyl4hlMfbwf8uTrq7dyu96j0RX86ILsODIG6h8RVM9GKEqV0icxWRGc6d8MCjr",
	"EUimJiuQRHRa66/8oh3E+XsFczTxI0cicmAwY84tB3OAh4SyKJx7JXL7HxCKk8qIsLRfuu13BNes/viv",
	"Hiwj+Zo54VU736/AEuk30DKysZeZPHeGeUo6zM3IkXg0MtI4Ct5YlL2ra/xnkj5g7/wAjCHD8gYUgZhi",
	"MtRuSzoKV9DEndyJ+sk7cHW0f2p1MM1B16UXDjHJW8gCMdk6nrn3q1qhZrK4pRI6ZaXRvGROxTfaod5u",
	"GYq8f1bKhMVtMYbfTVFmhNUEAzPrKmYR+iWzP4krzIz30J9pFG1T3zc0ZKHTUASTTShPpKb80LhY5HtL",
	"fBwiPGToMYAsSu+5+C7vq/YgivsEuiNISYQAveC02i7tyL9CAF2yGh1FFwfPmWA67P5lougSUBeG0m01",
	"m28LpUt7T8/F07mYvTGcbgbDcSidiaz7WQheNaZuz+gCfoSrKI51WSteYNNlkWfkjDFgGsTSW8ojVOen",
	"SzG6w0BRMLqCL2UK8Bz8xFRwLza6fYepdI2QvzaVp0Kk0y+qQxM/1ZmsQ6ukZkwT8TcnZ5xLLJmXnxHO",
	"JlVcLUOjQ12Up1fQX5K7lXmikmu0QCMceFBIumENrdO6KBC1AcahWfJPSUROZqao6Ufk7azuP36+yiIU",
	"+7BT3rQNS5VR0Z7+5yD0PCkNRdl/kvfVx4TGWYEyc+VOo9ykjPvljHnLJIS96F4zJNnN2JKKfIkVNLeY",
	"yk7l/+MV5NpNtAGjbuhY7GiX+sN8APIVcsERFGCfCMQChqXwjUn4Yk8LmOWgs0ZgzfFGCFOSJyZKstXZ",
	"arK4emvWpC8z9CT2wMy5hHm/52SWmGrA4ygxnVbso7yFHxVdKBm/8R+ZG2LpxU/d+TT3mvGyT+6+dbj0",
	"DUkNl54lZ7jYe+JHubY4hmuZTw6XdsiQPWAq2aPlNK7mmeHozESm+czA9gOmlvxv8O3VqP4ef6SDvYt1",
	"Y+I7exdGcQso6VPIlkXHu/jRHwwfNbqVAPboQ+dRMuw5+4pD8hiE/cdnNH0cQT5a3goTjhwjdi5uKbm9",
	"JL5i/sWCJJSSRKiA5YiNEXvMzQk9d/iVZWE9hHa1QiDOigU4Eiqlaa4kv0x+0eGsKWXDooxb1lX89TOV",
	"/ESpbokT0K8sKb+ypNguzILkKI/2Mh7y1/TazG3FBPSnIssA1TYaW43t+mZjOwtpaED9wRlVHnNTqiQr",
	"lXKhO7/cAV8QvZhapQ4p7E5gkLKz6ETjI6gsDyZnawJb1rCCXoQ8mi8DiajxQB1cPoGB1bjiwT7y7AT/",
	"O3PXWK7GrwDOrKkx8WNVNH25fiA6Q/YDaLPF/8rrs2Zen28LUNtNjfomrEZgKX9enfSTMilSyH9a+EOe",
	"Ym2sieRS4yWjpPApkEeQWA93GYZq2ay6cXbSgZAbR0SwZjxtLt4fokxLayB9FxMXwDgxBkFiQtkz0K7J",
	"Oi0GeKVE8WsMSagcAQSDgwF2lPqqR8SIchT3yFx6joTAZBjzZnIkG2dn17ik1UayZxHguWzc0bSKCsEg",
	"8KYqOVK6+k0yaY6L+YIrGg0fMTzKfpkbutILq9W6o/uof6N/VvRvPuTP+pcv/6t/OWu19Q//iwOOxEf9",
	"q/q3/n25I6ztLBy2L7/HZbwfOs9I5Cu/5Ksq2VzJBHavW+d7ras90BWUwSECjgc5B7tqiPJszQ3zR8nM",
	"sGZ9kTh5w0w8QezwJ4mmqijlgjb1g1AgsE+GmERhOz1yHRdAUAPNlCSZYDEygshh+xIYb9soNQTm6qXM",
	"Oi7o0CNdkChxPkxeydiTIqpV0iPvTPgTK8EAl/SWhyF29Y6/i9hrM53kVUUG6nVqmSRFkOZRKZeov6eq",
	"Q8Rril70tDdlCr/y1ht8qsJSMSqh/Bu7avQogUYZdBECsYO4R0O3PKR0aMIwuD46qqJEJa5IYorAZCuQ",
	"KCYi9AQuGcjjHB2ORzniIpIczP0jv5tCIdHx1Acz7vZeotmRtItkeZdZJKNwjVJrdjJi8KLWDaLmiu+S",
	"o2RPsu34quNZ7hEV82YOicK6cQtOpZaLpR0zjWHdbhUEWkLjADL0sUcAKIF3UgL6+AfyIfaw++3dR9CS",
	"jDPEHoCuyxDnWuZlKGCIKzk7MWbIIcDMsjTnabBXBO+ghx30P6nQm3dlM7N5H1u635ow6KnNEHlz+9OS",
	"chAqwSD4HxgEPKCiPDSdoj5pkJSIvS42zPqjujcSrhkUuJL7t+LApT7E5OMf+r9yQnU9QTfEAgH9K/g9",
	"YNiHbPp+fnLP0xNGeavMSwuF6TuLkeTqvZMs1bsZmOy3bvHRjGoFaeKgUjhBMu2RCL+9Gd5VHbi5U1GI",
	"mdHoPKy6eQWjUPk4j2ZlT1QITv/4U4o9xu/uj6sNo95mOf7jbO4JyB1EXEhEqc8gdkv1ar25UV8qpaeG",
	"Ky4rNXMY6ajWYB4W53EzZElrsRLt3+800MO/t+ZyW26Lmxnw7eUxOin/5TU46KjbEllQxSW6Wl5YxTt6",
	"P2qv/cy56FMqVu18EHewMolzc6xdTsg4iy2zhKh2i3B9kF7ZGiBYI+ouGR1jrh2Rwc3V6UqBcVbo0gH5",
	"P9+H7a2eZdrSu9TvW9l6f4onWrq+sFGeV+fME0ZJqRZZjJWTZXA3QiSqE1pNlyeTHbB8WH1MsB/6PaIz",
	"s7mgP021S9RGMY4btZ3GzuZWbWczT8up2fVHGqyUUiIrSSXdTflRO2+tlGIqpYDup2QVxbgGHpotYGqy",
	"GAjkR+nnegQCjgLIJHE0rV0kJS7N7KoHFgsO6IREU5TBmRm/R5LikGYOKUVMkJSOeQJG9C3KhSfp6bNS",
	"BTDUIzwM9Iu/hg+0xtW1GnfpQ5q5JZkLMHNKv0S3UWVSmPdWxAHyMFkqNZplmrhZEHUz0t3IyFmxE7we",
	"pS8FPiMTqoQUcSGosvWxjmAJQhYVs7aob/XH2CHKdNJ+6v9S4DFKxb9SMEIeOwloxcZ8Bgs3RJF/cJJz",
	"wzWDql+SAZXDe8RAakEhP9sF2AvjMHuiao0COugRTv30NVSqZSlG+lCFAcTHLJozc9B6xCChnNLGxyuP",
	"joNVDc/71F8hY0hkUnwn26tz9c6IPuVCcZ1USHH/BVfdrCwDQBm0syFJ3cu9z5KoJTcrtXYeuC/Lldpq",
	"7WmQijPH33IEk+uTw5WiyNli5VwZsc9AwOhQSkRLXQajdivn5khBbDJzxJR3tQGyKetmOq/x9s2Os5Cm",
	"RflBsihfKxVHUV8D/U8NtP53lPrd5OuYuxfZ2str8q9JRea1Skarqn7Win+eQEy+VuPIgzB2b0pIhj27",
	"MpzwVeL/+5Ar0702Tj0qX9JVg2Mls/loN3TvUiq0C0WiXtSSWbR5HhpCR6IiRANcKBZG0z5T0hShxE6x",
	"DGOUY8GN/PHSnI/FertR3apvNTa2a410EL1mamxCE3rJsTydq+2gA8CFLnA4ggJoJz6Uip6ioQhCYd+i",
	"XGHVFpmb4xIKCSXYgR6I2swjPDtfWUfBzXPOnD7GptmZY929AOoT+F1RYDmD/C31akmJk4Sep49Pxlsj",
	"bd/1Uc4TcNY528+8AfPQwyDwTHqYCnUEEiZhwupup51swfTs6D7+fg/QnNu52DE3dfmsqLnMOnrHg67g",
	"651EMqbD9vLjUaQIockMhwN9koyfUczPjTGMflPcpf1kpwNplp7uiPI/xr3SQsXMeU+bmmOxIBpBSzW5",
	"xHG5DTdiKd4OSjyEHZaU8s7U001FEM+m6StHiS7mPphyX29Xv+VrbhKxOPXS6scETnhpBEtsFGLzV+qf",
	"HAbxn6/6LTZ103W8rfo3gsFWplX2Dw4DGAR87sfoBxV+HmehNH9FmTnMD0lkebEwVPb8oRMPMAwRF7GS",
	"UHsFpztgKlSydnnRMkPLD/HE+o/sx9lRGJwk81BhDZovFAseHmchUII69EqaShsbcqYFdeRKghdUEpCV",
	"Xl4LxcKYB1JmSP5VomNYKBYm3MvhceQZPTFlTmachuZySbzBdNpJh/fPxHOGLi0RqqoFuOul/gkJFAIR",
	"d/UgypM4YcA6eqdAMpEWZkz9zgFkQ5NM0Uhz8sSopFMM6AwFKlMqJC6QEkTmASCU++IfA8oc9LZwCTNB",
	"XCohGVp/KbmoHw5Xy/51YpJhviEPWjLtgU6Z1PZo6JZ2IUcLwg+yPWvVWrW6U90qV61GQeXva0/n9Eyf",
	"sCWXk/x5FPZXyYIF+fOsKaBRs/F/qTCTBI76xlJ9qAE/maoY1TBI4k8irHzJ2ZsovfOs9UNeXpP6kKj0",
	"vXNu5kTTKd0yb/g8QVYxrqtgx3amItf77JA5Gcnl2zdEOVmmDJc//0VQAT3bpxksmNzmgSbCaryoczHX",
	"E79YUOlA1nP8WDRGHpYj7+zHyH938XnKNs+FG60psepOS+wtz2iqggvmKVMXGcVX1AR4cErDrONyaBVE",
	"PUiGoT08OjL16/Qtc7Xji8ZLl8lWBIE+cqjkWY1ptwh42Ofoa6g0cAQpEz3gyKHEhSatYIoNQ+Txplu+",
	"uT4obX+v89gpHUpRLK8AyTruuLEU5+kxTaUU46V7evt3dM9dWosmu9bFBWne7rVqEm79sPyfUYJLHTsZ",
	"OyjOur4Q6qIn601IqinOXC71e/6ItdqqZXPMDDZsXLQ730nr4hHyKF1uyM4q9kNjcrMlIhGICKvxsgVu",
	"rk61QUL5OSona5yo/sEACWeEyTBS1JdBR3LnkRbnXyHz/qVUzEhEJp9ij2gLRybvnrJHRZo+SrxpjnOk",
	"DnGxqm/kWAir3DvQZNgHv5tN/giqtc1qo19z4SbaaTb6br3R3+5v1+B2vYmacGvLrfU3q4MBfF/UQRh9",
	"BokzKnn4OR2Smoyn4lDjzKFSYHrfmw+7zbawM3SD+WQfK3Qz+XsWBwjtIYGYr2wdkxEyqNF+X+nkOsCH",
	"BA4RA787kLgeCjB5D7CLiMBiCnBKLSCo8qHRPkfZAoKgTQkPfcSAFLV1AuLZ7IqQA8fD8jnJthkh0iPx",
	"WYrPgWT8o4OVU59w9Si22ZjMv1JxmPwisb+qwP4Nq8Dat8GqIMjhWZcsJh+cYjLqIsgWQMVVBjy0tkbh",
	"Lf1s99SoUH84W2GUg/LMGQa4DA6wh8DQo/2+8XCOlY7FHkHDMninEhnyUem/3s1Qd+Hb8wPkZlO4MC5l",
	"cXaABXB1TEhB34PkWZd/0Gm1UwnoomHSBLYM7rDnOpC5hlePlmNW0yhvbJTnllIv1+HbPdTMfqVymsw7",
	"H1mPgpKOBfbz4uAX12dFAc0Z18MOMmmkVmV6M3oVS8U+X4pD1m/29ydzDFZiLOd1GTpT1iKUv8Ud0n5P",
	"IrNFTjQvJFDJfCVBqce/+6isX4cpL0XXHO3CQ99tLke6aWdPH2CfbPVzrTK989BfQAKiOx81BSGXBKh1",
	"enjx8ajVPVKOIdkquiNYa25+bNaaW9vbLqq7bqPR2NlyaltuY2Or1tzcrm9u9mvV+nYVbvY3t6pbgyrc",
	"2NmqNrbqqOHKf2zCxsAadZ57k952W/BQO+UsoP/fc2GM/WfZvSnGm6y2NMoQtXLxxtmY4GUVCdMVU5e1",
	"1c1MPmTrRUm5sax2Q7phP+XTMm8q6K/qGZMZyF7V6zL0Ai1NfldUF+TIHnG/a74ooTDJ2WJ8yRKRwy5O",
	"petF5Ca4kY+t0ukaFzzBEIpkRlVlO0eL/mgiLhT7tlA1PpsQMVqtdbtnEJon/6vqESspAeKWtulUXtec",
	"3JouGTwGKvvmKiflDJI4WyePEpVmE7c+GtlytdFyk51GYM8GSL8lqWpq/faJLpfNo8/O47Ox+y32G4st",
	"hPbJVjuwGb1yuUdaUUExla9Zc5LvTEGUd0XwLqmRof4ytTnegWQdSu/ZI32UiH6K8VSZn/WIvmYis4E3",
	"lLk6nitgyEGuUotgnepau+xCriJ3pbjfp2NraG2qcsufV7Bl7QItq6WkGQZDU3PJRP6Z3UgoUazQyNFh",
	"JMVbZqJULg/BM5om+RDwkCT+I0pEzqpgMhxDqRQXV748vASXN7unnTY42b8Hu6cX7RP1uUd6xP/UOd89",
	"bDldh+7ut/ZOB9v3R8/o9XgTut7Z/WQLHh52vGPoie3jp9pLZbd28mHUGXTCl0MR3D5toR45vRru3Wxt",
	"PsHrZnC71/QPzo7rwTMi6KriXPtfv356Pp9+4qPPNfrp82T/9abb32ifn7UH7cPh8+ftT7UeeX14Zh2n",
	"zQ6qn2oTdtL3YOiObj7gW0hae9zf2L7f/8r7zdZNfcsVN+ys/unevRvuXH34jC8Ht9tXPXKy+3RdrY9v",
	"dy/csy6/r++cwjbZ7AQbF+Ngu7NPKx20f3u/8dVvX1y24Em1f3xUDwfDRjtEz/zDdbdHJp/urlH79CV8",
	"ON28OPtMLy5PJuOzT4OX/nDj8972OHyonoininN+VHuBYfXF561w5+g4QM/ji8urF69Hpl/F0/RhwOgt",
	"RgfTYPIwHH+aCELOtivD7n5YOb69ZvfVZs3fv7neajv9rcazc3RwfTA4e/bI82GlR6qDm0brCjarjaP6",
	"y1P1WfRRfXziXH6mlxfhye4tP+qOq9Wbw/vW9BKF0w/bW85N5X5/dLb1XO/enjz1yCbqPAyn+OyiOvE2",
	"7g/3rk6c0Js8853Wh9B7Hm7Q636D11/9h/FldeuQXr/cNWpP8KR51/1wPnpAqEe2N6uf6e2o72ycBN0P",
	"T4MH+sTZvnjYvuzfPHy4Hx9sXwXMvWuxp6P+8XPtOLg6ab1cj174pxbfHR1u9Ej1NHyp3cGz3eqw1mle",
	"OmfuccX5+kSr247DnnY/h/jljuEmDnfOPgfbX68rg+7ruc/dzpBsV74+nPQI3v4UeoNwayv8OrqrTESt",
	"LwgWwyv+9Wn0chY+3d80HvqN0bM42B6d3FQ+f95q1L6OTpsnk9ZV61Nrt0fE3sHhw93V2PH3hyd7Zxsn",
	"3db2g3/73K8fj06vzzZOP+9O4d3GyCFeK/rdOToeQ//2yW03xz3i+M4H/On4Ynf3bLfdajUO8P4+Otr0",
	"2ejgaCu85Z9Oz85q1fum8zAiL/fbBy1f3aH24WT7oD157vTI7qRzePCJHrdbvL27e99uTfbbR8P99kGj",
	"1WoPnz8lvT+c37cqW7v3wdCbdlsP90ejp+nJqEcqHwabr5eD23H/qFbd/1p/7mxdHOyeV8np5w+7Nxt+",
	"OO5++Hoddut3p2y37tcPQ08EJ1f7xyenwm/u7/XIBjt8/dyi1xvTYOe+s33a2nPP2u2L6VPridO7m+2t",
	"+5uw/aHSJ0/sGl3VTq8u2oPpZXtr825nu4kvbnvEb3Y/9PmnvclWu3bKPLd11jjbC+n0YaOLxSF8aJx8",
	"Or0VH6734UYD8/vuYfvplW5d3m/f1o8vnpvVHhl+vRtu184rfb+2/9rdut6u3+3v9Te88VOj441fhp2v",
	"J2i4sfH6+f7FZ/fdh+Pj9mD8OvjgnXc3w5fhUY88vVSOq1PvoXaK+4ds87DVml7s3Nyx1kN30j2r7jtP",
	"19uT/TZ5ee7uhdOv/t3kdny++znc79xuX6D6fY+c4ZuNwfH5Nne39gJ+8NI8+/DZJWfkU/fDEXu6vjzZ",
	"q/t3zGu5ZP965N7fbj89PAd3o70pr1d2dtBFj4yeq+yUTKtP55NnGA4q+Gb7wtn8PD57fjq9OjseNm92",
	"bk+mx+HdnXidfCZPZ+fNu6uD3a8nDf5A/bOzHhmI/vXRxofmtH91V2nVx7t9+HJ1VxNbN6/nT84reu4+",
	"7GN4er5zWjlyjtudq41PB9ub27U9t+XtH+y4PfJcG37C991PLQiPq8fHrdej8dXz1fHp6fCkdv/pHh+d",
	"305ron48PRhwBv3mpNu+uxiMLlFnerp7/XDcI2MWnHuXfTTg1zvNretBbfe8Ew5fH1i7efuy1z15fhhe",
	"jTZuD8fdzifSnr4+f5pu7t/Uvl4G+K65I2nU6LLz+YGdUOekfnLa3ang1+NP11eeeDpr/aNH/nE5uN5S",
	"Jfp1kf4FT09OuRbK0CPnnv2R/lWcbFlxsiUGIZ1ohqey0IIB9rQXf+J0m+IpcniWxW6w59CX4wWJNyw3",
	"KYdTXBHkkqHhQIlc6WzEAWSiR36PAkfeW6tozIVwR9Ug6ZqVYn6sJS1rLAM5trIVUxZ2u0cnmjFcQ662",
	"spIt143dSyKrS8gRe8cBDMWIMvyKXCXPzOe443xUQm6t2dzYAa1Wq9Wun7/C9ob3sNfZOL/eb8rfOq3u",
	"HRbPF0eNm+2txr7Ld2/IVPTr/cn4ajg88j55/fvP3hbZqI53cspRWlPl3XBdQDUSf3RAAOcjtZABZVk9",
	"petjsjzAlit3MuP2O490JO+jUQLyPy/g9i3lH/ILI7Tk8VZSmrmDcdpsrtYncVcGXW0f4OC/wCQ2HKiQ",
	"PtW8CPqhUIkUBkm6Zz4Tf7mCV/rPrTWR8vpeVmpidm/XLzihzRzIjfGKiSbSceb0vfODNStPRKaT7yo5",
	"sXJ+sx+Qpwz0p1EiK3vUQlSDzrU/oKSju2z8kARmS6EhA+WGztcGxof8eVVYZNulkOiUbutixfo0pNVl",
	"84rCFao76RHSujD9FjqICXeNzrL5Im1ajppw/s7p7OzG4L2kKFKmQNAbNY5zw+RDP7vQeWNQKOijqbcM",
	"Z2yWi5/42V2wD61P+uM09NPaWQt/rJauy62tAULa3jBDH0wNrZnXRfkjyivgmNISLuACBTxy3NCh3tY4",
	"wNjpeMZ1U/4MYDzwasPNUEhXZ8LTU3xZXDArazEpdGeKjc1sgiPwWCdMN/xVJlkORw5DoiQ/pZh2FZlB",
	"mfW6q2hRqwp0XgO6giAQedxkhstL9Rw1ftS+WI8Boy/TRQ4LKqGaSciqGpsgLV07MBUHPFMMrGMmmnHf",
	"sS+BsiEkKY17OryhUa3X8lI2O6NHq+/iDPixElVJGVPjeiGckaoqunAlKrtFtJYcv0Q2cpYLETFIAw8O",
	"o6yBbOToPJZ67tTEUaI/6HFqSkCaJ4/PgLN0y7M531O8ferUlyX1T527VaI/TIWOnFQX8ycoXqVOyRWX",
	"+ND411bwfISstBMxTMpN7LthevOZmCFNmeNdnCUomR1KUYfUzbYxfdepKodrxCpE3ZZEKxARaKgWRBYQ",
	"EYCoUUYcr5YJZWJUgj5i2IHlgFKvTERQpmxYKBY2Fn1eS35PV3rM9/6KWhUjBk0xbTfX7YwAedOt7EO5",
	"22S1uK95+zeZrmCsb91199u12UQ+S/t06+t1mUu7unSO15Ch9brE9dzX62YJDVrWZc6/flmHPDeFb1/s",
	"dDlSUQ3xWNKiuSxHKr0o5oCPaOi5gCHlzNpXJXMvBkpUnt8knTRKxdEIlaXGsvdloMb1ESTGbx56HrA0",
	"BPrk8R6BDOlnQaug5uaFcVvzhowxVR6E2oQrAe4RFnpIF9BlaEAZKoIJ0oEw5mlSpxmoJDpydX0E4ARG",
	"BSewAJiTd6JHAso57uuQDR+/KLdtXz2typZs9gMIOlSKM0kt47uT5+qQChZfzV8nja44OcrKV2rFHrMJ",
	"Fde4UCv2mLlPK/aajRxZ92qs2G0+GE/5A62f/ybOoLNKfjmTxEsnmLPntylGXmHRsfkyc8DWzHjDQkLy",
	"0tpkcorNndu1F/Sd6d/sznEzQ37Jfbry8xOUeT2O+4/SEKRD9amDy4bE6FTGBVMl3o40o91dJ3Eno2GQ",
	"VRgmD7X6uLFKTow5cW0ldfY5OzzZZ2f3+MPZ2c0kPIJXrWP/6pR2Xq8Gta97NXev+VrdvX6pbL4siq1L",
	"h24itmGXYIyQOJ9kJfIP1w0AF5CpmAoxAr9t/lYEvzV/U8FKv9X6v8WV4/sIyA1RwTY9AglAxGHTQCiV",
	"pR6pDC4kHZ7gVMH5PgJCpSp1dTGapFBRj8T9snJcvni7qj9w2g9y7iaZGMZHHcO4uuY4GztqORHrR1/a",
	"pRs9Q7rU7e/2eJchIogp1OIBoD4WArnvc8PbftVZyamz4o395QnpDAGcPTy205c6B5YSRuqaqSi0kGCR",
	"LdxYA4d413rsVcE2LKZdeYj0od1FkGni11f/Oojuz/HdtZT7VEspret28agjIYLCt29KX6Pzp81GjOs0",
	"44Iaw6hK968jSEyatHIhEw1hFF+tADojBGoqW4TSCMQG9MlkUobqs7Jam768ctpp759390u1crU8Er6n",
	"5S6hkHHR3VXTm4R8DKh8+gAGOOWe/bFQK+h6hkR++Fiol6vljYKuuaXQVHE8ShCv/IHdb4r82yo+HJqT",
	"qp99VfsBmLdaHqxEGalTBSl7jIoFVZkdDf+uy5imDLmUqZOdJKpUSZvlyVdcAnJ1ZsS4ZmLH1aC0JcTd",
	"iAMJIIM+Ekpa/uccLd+L081GwAsKhqrmBCaKmIpR5NX+UQcNJsdaa3U0Yco+Kxu1Omo0N7dKaHunX9qo",
	"ufUSbDQ3S43a5maz2WhUq9Xq8tA5KRExYwxTm1GrVlOhwSaVS5wz7MmUnEwAWsjRprCkjnMWM2mcyCPS",
	"+IFTm7SQ85N2iJabzMkA2NVTb/z8qVuhKif3jJSvANaA6NnrP3/2G5KY++UJDBBT9Ynjs60hafwZkDwT",
	"OiEzW9D8M3b/hqCXQAegqlSjgDpOyORNS5NwdYsj4v3PL/KOxIFg6jFOEyFFvOLzpMapRH+omlvcFrOu",
	"k81DQNAk6loEAZVLx1GkLDeFbZS5cYwYjIi7ovdGS4GgM0qXxI51FnyecF1SLgytNkQGcbFL3emPu/F6",
	"9Mh14lv2jZbE7Nscvdn40bN3XNvWm48qu7Lip5H7byM6LMLPL8rzi/KsTHkM0bBRGl5ZyjhFJdWiHkr7",
	"N41SZMf8U9EQFhUHraR6ydXDsfxCGRgoFxg7T6QHPtVVZ38eU5GaxoLn2WX+umO/7tiar/v8EcrctEhM",
	"cZG8MDY/Mfl7Inyo11pKZlIMEPJouChAxEVEgCfat7zTeoTkpV5BvojmEhQYuP7zpQu9ZI2sfCkjwoxG",
	"yy9x4xdB+lsRpFlqoqIGv0tBsoZOJELZEmVIuh7DeuTq/5pCJIOpBcTqF5X6RaX+1koRq4wiOSet7E1r",
	"Riw6CtlkLfYnRaz+QlTkJ+hXUphRA//ZGpbU/HEMheVIqUpXaJKU5OyrglC6JGKO3kWgF1HRFfUz8Myi",
	"dmXq1fhRE9ju5reMZC7RkilGveACuHRCpISdK7HvmQbqVIMoabG+WANMMB+lXvEFD3I0zvoSRNLxb/cg",
	"Z6qaZLY5nqePCbSlkLEf46QIkbFfaiexGP+/3uhfb/TfQ5JIk5WYqmjHx+Q0z9Mrz2TQf4vUMUeuwEKZ",
	"A4tE1CgavQmn6gpmou1gn4bCpFrhoScW6iMl+L+EkuUKVYmnHBooj4Cd/qkKqoRqlxEn9CAzlQ3B72JE",
	"w+HIuKkedy/O35f/4x7+Q1XAf8hXuEY+JHiAuFh+l+KWK1ynKyRCRrjKBRX1U8Aou6Bhv4i5KoofNTVe",
	"48YOVRcrLsRiti+qcQsFSLuImJKlOrMCJBXzdykartxccBXPYhT8uo9L72OCrDzGJL3dqzImf/O7lr0e",
	"K1y6VL7RxXcuTkBv5bJ7RGIcvcgXM/0QMXX9kAu0Sp9HXm/mrsXuSMrXbdHNiOD8dTGWX4wIV78Y9l8M",
	"+38ywz5Hm5bTO96nfj6DETELEOiQpGyRaL6Eb+iRmeaQxW1UPemkpHWuiWD34mzNx1/CpOOYNJkD0Rj/",
	"R0wFarU5lE59/L/2/CeLnr0KLgo49caoklROXahm3jPtd1OFVn+G0jaaZy2vuOpPmD5fXxu1SZLbqCxn",
	"f/ZTGe3gLwe5+Qfz72OwNnuo0hMzHQga30jjTJPO1pR+r+Yejr1Uw5/tWTY3l+2ipNqATHqrvxljYRyS",
	"lO4uLrfsWlc3BW6Upmpu7yp/6BLM31bdxGWvfzpyfyanl+XFj+s/r/Lqq2RqO+VNW/jOLBgHKjMi6E/T",
	"Ahw4Cz2BAw/pDBI8iqZKsmhHUH4NkbIwRIyJHOPRBChZQPunKZ0OJ3y9+on5YKcToL0d8EwatRzQ47x2",
	"JpvlWiv48ifd5zjR2pIr7SYJ2f4UCSUzuU63F5K/nZRisGa4sjibZ+b+KtqhJllI8BWohtLPEArbCpMm",
	"FVWjNi+OPdVOh3b+zIOXrMHGasT+pQYZv3icf49SQB/4v59KAMYHSL7hcQaO6DQl12x5QCUkcSW/6M3V",
	"kCUlAeUL6NpEer3Mlb1zkGn+XWJ7/U8WwnO3Un0A6d9+3eJft3idW4zmT5C8uXGYdP4LeWGafOe5nwmK",
	"n1+oAUXRAoAJkEMYHd/fUYu6cDkS9To7ciWdADhfd5RNJ/yTFEf2fNR/svooJ3GyZbN0SxBBovMoRPqk",
	"DGP9J6qUeATUL4XS31Sh1I2zlptDhNyMDZaSFEuUyXmuAYoTGc5xJ2cQE/C7yT6MKXlv8hnOJceAAS6r",
	"crAjPNCJWWGAK0qqLyn/B8RKRhfNKuNaYV4w7wo4xGS4aAIu4BB95zQKt0QAl/pQ5cPX0ywb58u3/z8A",
	"AP//Z+dZyjMSAQA=",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
